{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"oneD_CNN(2).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMo4Btc2osyJRaiCP2XmRF+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"sK2y2FCZDPUY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605838928640,"user_tz":-480,"elapsed":69229,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}},"outputId":"06ef792b-8eb6-4aa2-fd14-9231ed13a600"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YR2Vx2acvmJk","executionInfo":{"status":"ok","timestamp":1605838943497,"user_tz":-480,"elapsed":2263,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras \n","import pandas as pd \n","import os \n","from sklearn.model_selection import StratifiedKFold \n","import gc \n","import random\n","import pickle \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","import albumentations as A \n","# 统计代码运行的时间\n","from time import *\n","begin_time = time()\n","\n","SEED = 2020\n","from tensorflow import random\n","os.environ['TF_DETERMINISTIC_OPS'] = '1'\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","np.random.seed(SEED)\n","random.set_seed(SEED)\n","\n","data_path = '/content/drive/My Drive/kesci_JZB/交子杯算法赛道—渣渣炼丹师队/code/data/'\n","model_path = '/content/drive/My Drive/kesci_JZB/交子杯算法赛道—渣渣炼丹师队/code/model/'\n","npy_path = '/content/drive/My Drive/kesci_JZB/交子杯算法赛道—渣渣炼丹师队/code/npy_file/'\n","pseudo_path = '/content/drive/My Drive/kesci_JZB/交子杯算法赛道—渣渣炼丹师队/code/pseudo_labels/'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"y-Ce-HuKgEg_","executionInfo":{"status":"ok","timestamp":1605838943498,"user_tz":-480,"elapsed":2258,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["def My_acc_combo(y, y_pred, mode): \n","    if mode== 'behavior':\n","        # 将行为ID转为编码\n","        code_y, code_y_pred = mapping[y], mapping[y_pred]\n","        if code_y == code_y_pred: # 编码完全相同得分1.0\n","            return 1.0\n","        elif code_y.split(\"_\")[0] == code_y_pred.split(\"_\")[0]: # 编码仅字母部分相同得分1.0/7\n","            return 1.0/7\n","        elif code_y.split(\"_\")[1] == code_y_pred.split(\"_\")[1]: # 编码仅数字部分相同得分1.0/3\n","            return 1.0/3\n","        else:\n","            return 0.0"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5z82N7EQzy-","executionInfo":{"status":"ok","timestamp":1605838943498,"user_tz":-480,"elapsed":1685,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["# 特征列名称\n","src_names = ['acc_x', 'acc_y', 'acc_z', 'acc_xg', 'acc_yg', 'acc_zg', 'acc', 'acc_g']\n","\n","def handle_features(data):\n","    data.drop(columns = ['time_point'], inplace=True)\n","\n","    data['acc'] = (data.acc_x ** 2 + data.acc_y ** 2 + data.acc_z ** 2) ** 0.5\n","    data['acc_g'] = (data.acc_xg ** 2 + data.acc_yg ** 2 + data.acc_zg ** 2) ** 0.5\n","\n","    return data\n","\n","# 构造numpy特征矩阵\n","def handle_mats(grouped_data):\n","    mats = [i.values for i in grouped_data] # i.values将i(每一个时序片段，但是长度不一)转化为数组\n","    # padding 填充 或者 重采样也可以。\n","    for i in range(len(mats)): \n","      padding_times = 61 - mats[i].shape[0] # 片段长度最多61，剩下的填充\n","      for j in range(padding_times):\n","        mats[i] = np.append(mats[i], [[0 for _ in range(mats[i].shape[1])]], axis=0) # _ 占位符，表示不在意变量的值，只是用于循环遍历n次\n","        # np.append(arr, values, axis=None) 为原始array添加一些values，这里是添加一行(1,mats[i].shape[1])元素全为0的二维数组\n","        # 当arr的维数为2，axis=0表示沿着行方向添加values；axis=1表示沿着列方向添加values\n","\n","    mats_padded = np.zeros([len(mats), 61, mats[0].shape[1]]) # 每个时序片段长度为61\n","    for i in range(len(mats)):\n","      mats_padded[i] = mats[i] \n","\n","    return mats_padded # 每个时序片段相同大小的三维数组\n","\n","def get_train_data(use_scaler=True, shuffle=False, pseudo_labels_file=None):\n","    df = pd.read_csv(data_path + \"sensor_train.csv\")\n","\n","    # 简单拼接伪标签\n","    if pseudo_labels_file != None:\n","      df = df.append(pd.read_csv(pseudo_labels_file)) # 测试集中，主模型预测概率最高(＞0.95)的数据，作为已知的数据标签\n","      # df1.append(df2)最简单的拼接数据的方式，注意行索引为各自对应的行索引\n","    data = handle_features(df)\n","\n","    # 标准化，并将统计值保存\n","    if use_scaler:\n","      scaler = StandardScaler()\n","      scaler.fit(data[src_names].values) # 用于计算训练数据的均值和方差，然后保存下来，用测试集的均值和方差来转换训练数据  scaler里面存的有计算出来训练集的均值和方差\n","      with open(pseudo_path + 'D_CNNscaler.pkl', 'wb') as f: # wb:以二进制格式打开一个文件只用于写入。如果该文件已存在则将其覆盖。如果该文件不存在，创建新文件。\n","        pickle.dump(scaler, f) \n","        # pickle.dumps(obj, file) 序列化对象，将对象obj保存到文件file中去。\n","        # file对象必须有write()接口，file可以是一个以'w'打开的文件或者是一个String对象，也可以是任何可以实现write()接口的对象。\n","      data[src_names] = scaler.transform(data[src_names].values) # 这一步是用训练数据的均值和方差来转换训练数据，使训练数据标准化\n","\n","    ######## 注意：在预测的时候，要用上面训练集fit得到的scaler中的均值和方差来对 \"测试集数据\" 进行标准化处理，即transform ########\n","\n","    grouped_data = [i.drop(columns='fragment_id') for _, i in data.groupby('fragment_id')]\n","    train_labels = np.array([int(i.iloc[0]['behavior_id']) for i in grouped_data]) # i.iloc[0]['behavior_id']第一行 str --> int\n","    for i in range(len(grouped_data)): \n","      grouped_data[i].drop(columns='behavior_id', inplace=True)\n","    train_data = handle_mats(grouped_data)\n","    \n","    if shuffle:\n","      index = [i for i in range(len(train_labels))]\n","      np.random.seed(SEED)\n","      np.random.shuffle(index)\n","\n","      train_data = train_data[index]\n","      train_labels = train_labels[index]\n","\n","    return train_data, train_labels\n","\n","def get_test_data(use_scaler=True):\n","    FILE_NAME = data_path + \"sensor_test.csv\"\n","    FILE_NAME1 = data_path + \"sensor_train.csv\"\n","    data = handle_features(pd.read_csv(FILE_NAME))\n","    train_ori = handle_features( pd.read_csv(FILE_NAME1)[['fragment_id', 'time_point', 'acc_x', 'acc_y', 'acc_z', 'acc_xg', 'acc_yg', 'acc_zg']] ) # 没有标签\n","\n","    if use_scaler:\n","      with open(pseudo_path + 'D_CNNscaler.pkl', 'rb') as f: # rb:以二进制格式打开一个文件用于只读。\n","        scaler = pickle.load(f) # 反序列化对象，将文件中的数据解析为一个python对象。file对象需要有read()接口和readline()接口。\n","      data[src_names] = scaler.transform(data[src_names].values)\n","      train_ori[src_names] = scaler.transform(train_ori[src_names].values)\n","\n","    grouped_data = [i.drop(columns='fragment_id') for _, i in data.groupby('fragment_id')]\n","    grouped_data1 = [i.drop(columns='fragment_id') for _, i in train_ori.groupby('fragment_id')]\n","    # data.groupby('fragment_id')得到(k,dataframe(k))，所以，i得到的是每个fragment_id所对应的dataframe\n","    return [handle_mats(grouped_data), handle_mats(grouped_data1)]\n","\n","def get_train_test_data(use_scaler=True, shuffle=True, pseudo_labels_file=None):\n","    train_data, train_lables = get_train_data(use_scaler, shuffle=False, pseudo_labels_file=pseudo_labels_file)\n","    test_data, train_ori = get_test_data(use_scaler) \n","    return train_data, train_lables, test_data, train_ori"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfnoKJZhdduJ","executionInfo":{"status":"ok","timestamp":1605838949514,"user_tz":-480,"elapsed":1553,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["kfcv_seed = 2020  \n","data_enhance_method = [] \n","mapping = { 0:'A_0', 1:'A_1', 2:'A_2', 3:'A_3', \n","        4:'D_4', 5:'A_5', 6:'B_1', 7:'B_5', \n","        8:'B_2', 9:'B_3', 10:'B_0', 11:'A_6', \n","        12:'C_1', 13:'C_3', 14:'C_0', 15:'B_6', \n","        16:'C_2', 17:'C_5', 18:'C_6' }\n","reversed_mapping = { value: key for key, value in mapping.items() } # 反字典\n","\n","\n","def set_data_enhance(val):\n","  if not isinstance(val, list): # isinstance()函数来判断val是否是list，若是，返回True，否则，返回False\n","    val = [val] # 非列表的转化为列表\n","  global data_enhance_method # 设置可以在函数中调用的全局变量 \n","  data_enhance_method = val\n","\n","## 获取行为对应的场景和动作编码\n","def decode_label(label_code):\n","  str = mapping[label_code] # 传入key，得到key值(字符串)\n","  scene_code = ord(str.split('_')[0]) - ord('A') # 比如：str.split('_')[0]='A'，则ord('A')=65 ord()函数以一个字符串作为参数，返回对应的ASCII数值\n","  action_code = ord(str.split('_')[1]) - ord('0') # ord('0')=48\n","  return scene_code, action_code \n","\n","## 交叉评估 \n","def kfcv_evaluate(model_name, x, y):\n","    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=kfcv_seed)\n","    evals = {'loss':0.0, 'accuracy':0.0}\n","\n","    for kfold_, (train, val) in enumerate(kfold.split(x, np.argmax(y, axis=-1))): # train、val为训练和验证集索引\n","\n","        print('Processing fold: %d (%d, %d)' % (kfold_, len(train), len(val)))\n","        model = keras.models.load_model(model_path + '%s/part_%d.h5' % (model_name, kfold_)) # 加载每一折训练的最优模型\n","        loss, acc = model.evaluate(x[val], y[val]) # 返回的是损失值和选定的指标值(精度)\n","        evals['loss'] += loss / k # 交叉验证的损失取平均\n","        evals['accuracy'] += acc / k # # 交叉验证的精度取平均\n","\n","    return evals \n","\n","## 交叉预测\n","def kfcv_predict(model_name, inputs):\n","  # path = model_path + model_name + '/'\n","  models = []\n","  for i in range(k):\n","    # models.append(keras.models.load_model(path + 'part_%d.h5' % i)) \n","    models.append(keras.models.load_model(model_path + '%s/part_%d.h5' % (model_name, i)))\n","  print('%s loaded.' % model_name) \n","  result = [] \n","  for j in range(k):\n","    result.append(models[j].predict(inputs)) # inputs为测试集\n","\n","  print('result got')\n","  result = sum(result) / k # 交叉验证的预测结果取平均，类似单模stacking\n","  return result \n","\n","\n","## 白噪声(noise)、混合(mixup)、黑色正方块(cutout)\n","def data_enhance(method, train_data, train_labels): # train_labels：(?, 19)\n","\n","    if method == 'noise':\n","      noise = train_data + np.random.normal(loc = 0, scale = 0.1, size = train_data.shape) \n","      # 均值、标准差 正态分布的标准差，对应分布的宽度，scale越大，正态分布的曲线越矮胖，scale越小，曲线越高瘦。\n","      return noise, train_labels \n","\n","    elif method == 'cutout': \n","      cutout = np.zeros((train_data.shape[0], train_data.shape[1], train_data.shape[2]))\n","      for i in range(train_data.shape[0]):  \n","        transform = A.Cutout(num_holes=8, max_h_size=1, max_w_size=1, always_apply=False, p=0.5) # Cutout 剪下8个正方形的小黑块\n","        cutout[i, :, :] = transform(image = train_data[i, :, :])['image'] # 生成一个裁剪之后的图片\n","      train_data = np.vstack((train_data, cutout)) # 多维数组垂直堆叠\n","      train_labels = np.vstack((train_labels, train_labels)) # y为标签，一维数组，可以水平堆叠\n","      return train_data, train_labels \n","\n","    elif method == 'mixup': # 几乎无额外计算开销的情况下稳定提升1个百分点的图像分类精度\n","      index = [i for i in range(len(train_labels))] \n","      np.random.shuffle(index) # 打乱索引 \n","\n","      x_mixup = np.zeros(train_data.shape)\n","      y_mixup = np.zeros(train_labels.shape)\n","\n","      for i in range(len(train_labels)):\n","        x1 = train_data[i] # 每一个图片\n","        x2 = train_data[index[i]] # 随机打乱的索引所对应的图片\n","        y1 = train_labels[i] \n","        y2 = train_labels[index[i]]\n","\n","        factor = np.random.beta(0.2, 0.2) # 得到一个趋近于0或者1的概率 https://zhuanlan.zhihu.com/p/24555092\n","        # beta分布就是抛硬币a次正，b次反后，硬币正面概率的分布，当a,b都小时，概率要么趋近于0，要么趋近于1\n","        x_mixup[i] = x1 * factor + x2 * (1 - factor) # 把混合之后的图片作为第i个图片\n","        y_mixup[i] = y1 * factor + y2 * (1 - factor) # 标签也是\n","\n","      return x_mixup, y_mixup \n","\n","\n","def shuffle(data, labels, seed=None):\n","    index = [i for i in range(len(labels))]\n","    if seed != None:\n","      np.random.seed(seed) \n","    np.random.shuffle(index) # 打乱索引列表\n","    return data[index], labels[index]\n"," \n","## 交叉拟合\n","def kfcv_fit(builder, x, y, epochs, checkpoint_path, verbose=2, batch_size=64): # checkpoint_path --> 传入model_path\n","    kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=kfcv_seed)\n","    histories = [] # 历史记录\n","    evals = [] # 评估标准\n","\n","    if checkpoint_path[len(checkpoint_path) - 1] != '/': # 路径字符串最后一个字符如果不是 '/'\n","      checkpoint_path += '/' # 拼接\n","\n","    for i in range(k):\n","      if os.path.exists(checkpoint_path + 'part_%d.h5' % i): # 如果路径path存在，返回True；如果路径path不存在，返回False。\n","        os.remove(checkpoint_path + 'part_%d.h5' % i) # os.remove()方法用于删除指定路径的文件。\n","\n","    for index, (train, val) in enumerate(kfold.split(x, np.argmax(y, axis=-1))):\n","        print('Processing fold: %d (%d, %d)' % (index, len(train), len(val)))\n","        model = builder()\n","\n","        x_train = x[train] # 分折训练的数据\n","        y_train = y[train]\n","\n","        if len(data_enhance_method) > 0:\n","          x_train_copy = np.copy(x_train)\n","          y_train_copy = np.copy(y_train)\n","          for method in data_enhance_method: \n","            x_, y_ = data_enhance(method, x_train_copy, y_train_copy)\n","            x_train = np.r_[x_train, x_] # np.r_ 按行拼接矩阵，要求列数相同 a = [[1,2,3],[7,8,9]] b = [[4,5,6],[1,2,3]] np.r_[a,b] --> (4,3)\n","            y_train = np.r_[y_train, y_] \n","          x_train, y_train = shuffle(x_train, y_train) # 打乱数据\n","          print('Data enhanced (%s) => %d' % (' '.join(data_enhance_method), len(x_train)))\n","        # ' '.join(data_enhance_method)把list里的字符串元素用' '拼接成一个字符串，比如：data_enhance_method=['noise','cutout'] --> 'noise cutout'\n","        plateau = ReduceLROnPlateau(monitor = 'val_acc', verbose = 0, mode = 'max', factor = 0.1, patience = 8) # 'val_acc_combo'\n","        early_stopping = EarlyStopping(monitor = 'val_acc', verbose = 0, mode = 'max', patience = 20) # 防止过拟合\n","        checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path + 'part_%d.h5' % index,\n","                                 monitor='val_accuracy',\n","                                 verbose=0,\n","                                 mode='max',\n","                                 save_best_only=True)\n","\n","        h = model.fit(x_train, \n","                y_train,\n","                epochs=epochs,\n","                verbose=verbose,\n","                validation_data=(x[val], y[val]),\n","                callbacks=[plateau, early_stopping, checkpoint],\n","                batch_size=batch_size,\n","                shuffle=True) \n","        evals.append(model.evaluate(x=x[val], y=y[val])) # model.evaluate 返回一个列表\n","        histories.append(h) \n","        del model\n","        gc.collect() \n","    return histories, evals \n","\n","\n","def save_results(path, output): \n","    print('saving...')\n","    df_r = pd.DataFrame(columns=['fragment_id', 'behavior_id'])\n","    for i in range(len(output)):\n","      behavior_id = output[i] # 遍历预测的行为列表\n","      df_r = df_r.append({'fragment_id': i, 'behavior_id': behavior_id}, ignore_index=True) \n","      # 向dataframe对象中添加新的行，通过设置ignore_index=True来避免index出现重复的情况。\n","    df_r.to_csv(path, index=False)\n","\n","\n","def infer(model_name, inputs, csv_output): # csv_output --> data_path\n","    output = np.argmax(kfcv_predict(model_name, inputs), axis=-1) \n","    save_results(csv_output, output) \n","    print('- END -')\n","    print('Your file locates at %s' % csv_output)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHDGmzp0veBd","executionInfo":{"status":"ok","timestamp":1605838956299,"user_tz":-480,"elapsed":2006,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["def BLOCK(seq, filters, kernal_size): \n","    cnn = keras.layers.Conv1D(filters, 1, padding='SAME', activation='relu')(seq) # (?, 61, 8) --> (?, 61, 128)\n","    cnn = keras.layers.LayerNormalization()(cnn) # LN：取的是同一个样本的不同通道做归一化，根据样本的特征数做归一化 BN：取不同样本的同一个通道的特征做归一化 \n","    # 参考：https://zhuanlan.zhihu.com/p/54530247 \n","    cnn = keras.layers.Conv1D(filters, kernal_size, padding='SAME', activation='relu')(cnn) # (?, 61, 128) --> (?, 61, 128)\n","    cnn = keras.layers.LayerNormalization()(cnn) # 输入下一层之前进行层归一化\n","\n","    cnn = keras.layers.Conv1D(filters, 1, padding='SAME', activation='relu')(cnn) # (?, 61, 128) --> (?, 61, 128)\n","    cnn = keras.layers.LayerNormalization()(cnn)\n","\n","    seq = keras.layers.Conv1D(filters, 1)(seq)  \n","    seq = keras.layers.Add()([seq, cnn]) # 该层接收一个相同shape列表张量，并返回它们的和，shape不变。 高层特征与底层特征进行融合\n","    # [(?, 61, 128), (?, 61, 128)] --> (?, 61, 128)\n","    return seq\n","\n","def BLOCK2(seq, filters=128, kernal_size=3):\n","    seq = BLOCK(seq, filters, kernal_size) \n","    seq = keras.layers.AveragePooling1D(2)(seq) # (?, 61, 128) --> (?, 30, 128)\n","    seq = keras.layers.SpatialDropout1D(0.3)(seq) \n","    # 它断开的是整个1D特征图，而不是单个神经元。\n","    # 如果一张特征图的相邻像素之间有很强的相关性（通常发生在低层的卷积层中），那么普通的dropout无法正则化其输出，否则就会导致明显的学习率下降。\n","    # 这种情况下，SpatialDropout1D能够帮助提高特征图之间的独立性，应该用其取代普通的Dropout\n","    seq = BLOCK(seq, filters//2, kernal_size) # 两个斜杠即双斜杠（//）表示地板除，即先做除法（/），然后向下取整（floor），比如：3 // 2 = 1\n","    # [(?, 30, 64), (?, 30, 64)] --> (?, 30, 64)\n","    seq = keras.layers.GlobalAveragePooling1D()(seq) # (?, 30, 64) --> (?, 64)\n","    return seq\n","\n","def ComplexConv1D(input_shape, num_classes):\n","    inputs = keras.layers.Input(shape=input_shape[1:]) # input_shape --> (10866, 61, 8) input_shape[1:] --> (61, 8)\n","    seq_3 = BLOCK2(inputs, kernal_size=3) # (?, 30, 64) --> (?, 64)\n","    seq_5 = BLOCK2(inputs, kernal_size=3) # (?, 30, 64) --> (?, 64)\n","    seq_7 = BLOCK2(inputs, kernal_size=3) # (?, 30, 64) --> (?, 64)\n","    seq = keras.layers.concatenate([seq_3, seq_5, seq_7]) # [(?, 64), (?, 64), (?, 64)] --> (?, 192)\n","    ## 用CNN1D提取时序特征之后，再用普通的隐层进行拟合\n","    seq = keras.layers.Dense(512, activation='relu')(seq) # (?, 192) --> (?, 512) \n","    seq = keras.layers.Dropout(0.3)(seq) \n","    seq = keras.layers.Dense(128, activation='relu')(seq) # (?, 512) --> (?, 128) \n","    seq = keras.layers.Dropout(0.3)(seq)\n","    outputs = keras.layers.Dense(num_classes, activation='softmax')(seq) # (?, 128) --> (?, 19)  \n","\n","    return keras.models.Model(inputs=[inputs], outputs=[outputs])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXkAk7aUMdTb","executionInfo":{"status":"ok","timestamp":1605839175316,"user_tz":-480,"elapsed":30370,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["# 导入主模型挑选的pseudo labels，这么做的目的是把从主模型预测准确率较高的测试集样本提取出来，跟原训练数据进行拼接，作为新模型的训练数据\n","train_data, train_labels, test_data, train_ori = get_train_test_data(pseudo_labels_file = pseudo_path + 'pseudo_labels.csv') # array\n","# train_data --> (10866, 61, 8) train_labels --> (10866,) test_data --> (7500, 61, 8) train_ori --> (7292, 61, 8)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"eahSGEdNeJO8","executionInfo":{"status":"ok","timestamp":1605839178789,"user_tz":-480,"elapsed":1297,"user":{"displayName":"余凯","photoUrl":"","userId":"13334016005065607071"}}},"source":["cv = 20\n","la = pd.read_csv(data_path + \"sensor_train.csv\")\n","y_train = la.groupby('fragment_id')['behavior_id'].min()\n","checkpoint_path = model_path\n","\n","for i in range(cv): # 5折\n","  if os.path.exists(checkpoint_path + 'part_%d.h5' % i):\n","    os.remove(checkpoint_path + 'part_%d.h5' % i)\n","## 原训练数据及标签 \n","x = train_data[ : 7292] \n","y = train_labels[ : 7292] # (7292, )\n","y_ = to_categorical(y, num_classes=19) # (7292, 19) \n","## 由主模型得到的伪训练数据及标签 \n","wei_train_x = train_data[7292 : ]\n","wei_label_y = train_labels[7292 : ]\n","wei_label_y_ = to_categorical(wei_label_y, num_classes=19)\n","\n","proba_t = np.zeros((7500, 19))\n","valid = np.zeros((7292, 19)) "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyiN_BcEveDw","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4b6be419-338b-43d7-99b5-5695a3580512"},"source":["cv = 20\n","la = pd.read_csv(data_path + \"sensor_train.csv\")\n","y_train = la.groupby('fragment_id')['behavior_id'].min()\n","checkpoint_path = model_path\n","\n","for i in range(cv): # 5折\n","  if os.path.exists(checkpoint_path + 'part_%d.h5' % i):\n","    os.remove(checkpoint_path + 'part_%d.h5' % i)\n","## 原训练数据及标签 \n","x = train_data[ : 7292] \n","y = train_labels[ : 7292] # (7292, )\n","y_ = to_categorical(y, num_classes=19) # (7292, 19) \n","## 由主模型得到的伪训练数据及标签 \n","wei_train_x = train_data[7292 : ]\n","wei_label_y = train_labels[7292 : ]\n","wei_label_y_ = to_categorical(wei_label_y, num_classes=19)\n","\n","proba_t = np.zeros((7500, 19))\n","valid = np.zeros((7292, 19)) \n","\n","## 为伪标签创建20折，然后训练时分配下去\n","valid_fold = [] # 每个元素为一个索引list 比如：(179,)\n","kfold1 = StratifiedKFold(n_splits=cv, shuffle=True, random_state=2020) \n","for index, (train, val) in enumerate(kfold1.split(wei_train_x, wei_label_y)):\n","  valid_fold.append(val) \n","\n","## 原数据 20折交叉验证 验证trick是否有提升\n","kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=2020)  \n","## 总结：对shuffle=True设置random_state=2020之后，每次结果都是固定的，它只会随着不同的种子而改变。\n","## 如果想要每次打乱的结果都是不一样的，只需要设置shuffle=True，而不需要设置随机种子\n","## 因此，验证trick是否有提升的时候，必须要在设置固定随机种子的基础上再进行对比。\n","for index, (train, val) in enumerate(kfold.split(x, y)):\n","  print('Processing fold: %d (%d, %d)' % (index, len(train), len(val))) # (6927, 365)\n","  model = ComplexConv1D(train_data.shape, 19) \n","  model.compile(optimizer='Nadam', loss=tf.losses.CategoricalCrossentropy(label_smoothing=0.1), metrics=['accuracy']) \n","  ## 无数据增强 \n","  # x_train, y_train = x[train], y_[train]\n","  ########################### 训练数据增强 ###########################\n","  ## 噪音增强\n","  # x_train, y_train = data_enhance('noise', x[train], y_[train])\n","  ## mixup增强：几乎无额外计算开销的情况下稳定提升1个百分点的图像分类精度\n","  # x_train, y_train = data_enhance('mixup', x[train], y_[train])\n","  ## cutout增强：数据变成原来的两倍\n","\n","  x_train, y_train = data_enhance('cutout', x[train], y_[train]) # x_train：(13854, 61, 8) y_train：(13854, 19)\n","  \n","  ## 再加上半监督增强\n","  # x_train = np.vstack([x_train, wei_train_x[valid_fold[index]]]) # 6927/13854 + 179 = 7106/14033 每一次只增加伪标签数据的一部分(验证集大小) \n","  # y_train = np.vstack([y_train, wei_label_y_[valid_fold[index]]]) \n","  x_train = np.vstack([x_train, wei_train_x]) # 6927/13854 + 3474 = 10466/17328\n","  y_train = np.vstack([y_train, wei_label_y_]) \n","  \n","  # 原始数据(7292) + 半监督增强(179) 0.86301  \n","  # cutout增强数据(7292 * 2) + 半监督增强(179) 0.87671\n","  # 原始数据(7292) + 半监督增强(3474) 0.87671 \n","  # 噪音增强数据(7292) + 半监督增强(3474) 0.84384\n","  # mixup增强数据(7292) + 半监督增强(3474) 0.86301\n","  # cutout增强数据(7292 * 2) + 半监督增强(3474) 0.89041 \n","\n","  graph_path = model_path + 'ComplexConv1D_model.png'\n","  plot_model(model, to_file = graph_path, show_shapes = True)  # 绘制模型图\n","  \n","  early_stopping = EarlyStopping(monitor='val_accuracy', verbose=0, mode='max', patience=20)\n","  checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path + 'part_%d.h5' % index, monitor='val_accuracy', verbose=0, mode='max', save_best_only=True)\n","  plateau = ReduceLROnPlateau(monitor=\"val_accuracy\", verbose=0, mode='max', factor=0.1, patience=8) \n","  h = model.fit(x=x_train, \n","          y=y_train, \n","          epochs=500,  \n","          verbose=1,  \n","          validation_data=(x[val], y_[val]),\n","          callbacks=[checkpoint,early_stopping,plateau], \n","          batch_size=64,\n","          shuffle=True)\n","  \n","  model.load_weights(checkpoint_path + 'part_%d.h5' % index)\n","\n","  # 单模stacking\n","  valid[val] += model.predict(x[val])\n","  proba_t += model.predict(test_data) / cv\n","\n","  # 计算验证集精确率\n","  val_ = model.predict(x[val])\n","  print('准确率得分：', round(accuracy_score(y[val], np.argmax(val_, axis=1)), 5))\n","\n","  del model\n","  gc.collect()\n","\n","# 计算执行时间 \n","end_time = time()\n","run_time = (end_time - begin_time) / 60\n","print('该循环程序运行时间：', run_time, '分钟') \n","\n","np.save(npy_path + 'oneD_CNN_valid', valid)\n","np.save(npy_path + 'oneD_CNN_test', proba_t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing fold: 0 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 71ms/step - loss: 2.0021 - accuracy: 0.4331 - val_loss: 1.7111 - val_accuracy: 0.5041\n","Epoch 2/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.6432 - accuracy: 0.5702 - val_loss: 1.5115 - val_accuracy: 0.6055\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.4840 - accuracy: 0.6406 - val_loss: 1.4001 - val_accuracy: 0.6822\n","Epoch 4/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3825 - accuracy: 0.6885 - val_loss: 1.3365 - val_accuracy: 0.7288\n","Epoch 5/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.3147 - accuracy: 0.7175 - val_loss: 1.2798 - val_accuracy: 0.7014\n","Epoch 6/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.2492 - accuracy: 0.7503 - val_loss: 1.2503 - val_accuracy: 0.7205\n","Epoch 7/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1998 - accuracy: 0.7748 - val_loss: 1.1904 - val_accuracy: 0.7479\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1617 - accuracy: 0.7871 - val_loss: 1.1398 - val_accuracy: 0.8027\n","Epoch 9/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.1243 - accuracy: 0.8083 - val_loss: 1.0967 - val_accuracy: 0.7918\n","Epoch 10/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0817 - accuracy: 0.8261 - val_loss: 1.1423 - val_accuracy: 0.7836\n","Epoch 11/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0598 - accuracy: 0.8347 - val_loss: 1.1374 - val_accuracy: 0.7836\n","Epoch 12/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0253 - accuracy: 0.8489 - val_loss: 1.0648 - val_accuracy: 0.7890\n","Epoch 13/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0017 - accuracy: 0.8613 - val_loss: 1.1031 - val_accuracy: 0.7918\n","Epoch 14/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9878 - accuracy: 0.8660 - val_loss: 1.1007 - val_accuracy: 0.8137\n","Epoch 15/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9591 - accuracy: 0.8819 - val_loss: 1.0576 - val_accuracy: 0.8192\n","Epoch 16/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9466 - accuracy: 0.8846 - val_loss: 1.0777 - val_accuracy: 0.8110\n","Epoch 17/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9278 - accuracy: 0.8964 - val_loss: 1.0725 - val_accuracy: 0.8137\n","Epoch 18/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9084 - accuracy: 0.9061 - val_loss: 1.0502 - val_accuracy: 0.8137\n","Epoch 19/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8870 - accuracy: 0.9123 - val_loss: 0.9740 - val_accuracy: 0.8685\n","Epoch 20/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8699 - accuracy: 0.9193 - val_loss: 1.1012 - val_accuracy: 0.8219\n","Epoch 21/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8659 - accuracy: 0.9241 - val_loss: 0.9801 - val_accuracy: 0.8521\n","Epoch 22/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8535 - accuracy: 0.9262 - val_loss: 1.0343 - val_accuracy: 0.8274\n","Epoch 23/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8324 - accuracy: 0.9356 - val_loss: 1.0169 - val_accuracy: 0.8219\n","Epoch 24/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8306 - accuracy: 0.9369 - val_loss: 1.0169 - val_accuracy: 0.8329\n","Epoch 25/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8203 - accuracy: 0.9400 - val_loss: 1.0083 - val_accuracy: 0.8384\n","Epoch 26/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8059 - accuracy: 0.9474 - val_loss: 1.0031 - val_accuracy: 0.8411\n","Epoch 27/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7983 - accuracy: 0.9491 - val_loss: 1.0111 - val_accuracy: 0.8438\n","Epoch 28/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7470 - accuracy: 0.9711 - val_loss: 0.9544 - val_accuracy: 0.8685\n","Epoch 29/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7278 - accuracy: 0.9782 - val_loss: 0.9477 - val_accuracy: 0.8630\n","Epoch 30/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7201 - accuracy: 0.9808 - val_loss: 0.9500 - val_accuracy: 0.8658\n","Epoch 31/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7159 - accuracy: 0.9814 - val_loss: 0.9524 - val_accuracy: 0.8658\n","Epoch 32/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7116 - accuracy: 0.9851 - val_loss: 0.9642 - val_accuracy: 0.8712\n","Epoch 33/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7109 - accuracy: 0.9838 - val_loss: 0.9541 - val_accuracy: 0.8658\n","Epoch 34/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7078 - accuracy: 0.9853 - val_loss: 0.9700 - val_accuracy: 0.8603\n","Epoch 35/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7043 - accuracy: 0.9858 - val_loss: 0.9736 - val_accuracy: 0.8548\n","Epoch 36/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7025 - accuracy: 0.9869 - val_loss: 0.9655 - val_accuracy: 0.8630\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7004 - accuracy: 0.9878 - val_loss: 0.9528 - val_accuracy: 0.8685\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6974 - accuracy: 0.9874 - val_loss: 0.9756 - val_accuracy: 0.8575\n","Epoch 39/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6969 - accuracy: 0.9888 - val_loss: 0.9595 - val_accuracy: 0.8685\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6956 - accuracy: 0.9880 - val_loss: 0.9636 - val_accuracy: 0.8630\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6893 - accuracy: 0.9902 - val_loss: 0.9632 - val_accuracy: 0.8575\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6904 - accuracy: 0.9893 - val_loss: 0.9609 - val_accuracy: 0.8575\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6876 - accuracy: 0.9916 - val_loss: 0.9636 - val_accuracy: 0.8575\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6873 - accuracy: 0.9911 - val_loss: 0.9626 - val_accuracy: 0.8630\n","Epoch 45/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6886 - accuracy: 0.9903 - val_loss: 0.9655 - val_accuracy: 0.8630\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6891 - accuracy: 0.9909 - val_loss: 0.9616 - val_accuracy: 0.8685\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6858 - accuracy: 0.9925 - val_loss: 0.9638 - val_accuracy: 0.8603\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6870 - accuracy: 0.9910 - val_loss: 0.9649 - val_accuracy: 0.8603\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6868 - accuracy: 0.9920 - val_loss: 0.9641 - val_accuracy: 0.8603\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6856 - accuracy: 0.9914 - val_loss: 0.9642 - val_accuracy: 0.8603\n","Epoch 51/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6852 - accuracy: 0.9916 - val_loss: 0.9644 - val_accuracy: 0.8603\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6868 - accuracy: 0.9913 - val_loss: 0.9644 - val_accuracy: 0.8603\n","准确率得分： 0.87123\n","Processing fold: 1 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.9968 - accuracy: 0.4340 - val_loss: 1.7820 - val_accuracy: 0.5315\n","Epoch 2/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.6523 - accuracy: 0.5671 - val_loss: 1.5950 - val_accuracy: 0.5616\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.4955 - accuracy: 0.6386 - val_loss: 1.4982 - val_accuracy: 0.5781\n","Epoch 4/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3923 - accuracy: 0.6824 - val_loss: 1.4312 - val_accuracy: 0.6575\n","Epoch 5/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.3172 - accuracy: 0.7143 - val_loss: 1.4041 - val_accuracy: 0.6575\n","Epoch 6/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2632 - accuracy: 0.7427 - val_loss: 1.3240 - val_accuracy: 0.6904\n","Epoch 7/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.2055 - accuracy: 0.7661 - val_loss: 1.2277 - val_accuracy: 0.7479\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1658 - accuracy: 0.7833 - val_loss: 1.1933 - val_accuracy: 0.7507\n","Epoch 9/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.1291 - accuracy: 0.8051 - val_loss: 1.1966 - val_accuracy: 0.7534\n","Epoch 10/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0999 - accuracy: 0.8166 - val_loss: 1.2579 - val_accuracy: 0.7260\n","Epoch 11/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0707 - accuracy: 0.8274 - val_loss: 1.1899 - val_accuracy: 0.7479\n","Epoch 12/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0419 - accuracy: 0.8435 - val_loss: 1.1505 - val_accuracy: 0.7671\n","Epoch 13/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0146 - accuracy: 0.8556 - val_loss: 1.1381 - val_accuracy: 0.7890\n","Epoch 14/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9903 - accuracy: 0.8650 - val_loss: 1.2111 - val_accuracy: 0.7589\n","Epoch 15/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.9735 - accuracy: 0.8721 - val_loss: 1.1356 - val_accuracy: 0.7836\n","Epoch 16/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9401 - accuracy: 0.8877 - val_loss: 1.1234 - val_accuracy: 0.7836\n","Epoch 17/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.9311 - accuracy: 0.8920 - val_loss: 1.0781 - val_accuracy: 0.8055\n","Epoch 18/500\n","273/273 [==============================] - 20s 71ms/step - loss: 0.9116 - accuracy: 0.8993 - val_loss: 1.0708 - val_accuracy: 0.8164\n","Epoch 19/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8952 - accuracy: 0.9082 - val_loss: 1.1179 - val_accuracy: 0.7945\n","Epoch 20/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8754 - accuracy: 0.9151 - val_loss: 1.0673 - val_accuracy: 0.8110\n","Epoch 21/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8604 - accuracy: 0.9225 - val_loss: 1.0715 - val_accuracy: 0.8301\n","Epoch 22/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8514 - accuracy: 0.9276 - val_loss: 1.0989 - val_accuracy: 0.8219\n","Epoch 23/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8448 - accuracy: 0.9296 - val_loss: 1.0559 - val_accuracy: 0.8274\n","Epoch 24/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8346 - accuracy: 0.9333 - val_loss: 1.0573 - val_accuracy: 0.8274\n","Epoch 25/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8196 - accuracy: 0.9393 - val_loss: 1.0739 - val_accuracy: 0.8192\n","Epoch 26/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8154 - accuracy: 0.9429 - val_loss: 1.0656 - val_accuracy: 0.8137\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7981 - accuracy: 0.9485 - val_loss: 1.0636 - val_accuracy: 0.8055\n","Epoch 28/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7978 - accuracy: 0.9471 - val_loss: 1.0799 - val_accuracy: 0.8247\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7844 - accuracy: 0.9558 - val_loss: 1.1112 - val_accuracy: 0.8082\n","Epoch 30/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7371 - accuracy: 0.9757 - val_loss: 1.0360 - val_accuracy: 0.8301\n","Epoch 31/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.7188 - accuracy: 0.9808 - val_loss: 1.0136 - val_accuracy: 0.8356\n","Epoch 32/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.7148 - accuracy: 0.9831 - val_loss: 1.0105 - val_accuracy: 0.8411\n","Epoch 33/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7102 - accuracy: 0.9846 - val_loss: 1.0111 - val_accuracy: 0.8384\n","Epoch 34/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7058 - accuracy: 0.9855 - val_loss: 1.0145 - val_accuracy: 0.8384\n","Epoch 35/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7028 - accuracy: 0.9867 - val_loss: 1.0133 - val_accuracy: 0.8411\n","Epoch 36/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.6995 - accuracy: 0.9877 - val_loss: 1.0045 - val_accuracy: 0.8521\n","Epoch 37/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6995 - accuracy: 0.9871 - val_loss: 1.0078 - val_accuracy: 0.8493\n","Epoch 38/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6960 - accuracy: 0.9887 - val_loss: 1.0143 - val_accuracy: 0.8466\n","Epoch 39/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6929 - accuracy: 0.9898 - val_loss: 1.0196 - val_accuracy: 0.8438\n","Epoch 40/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6937 - accuracy: 0.9890 - val_loss: 1.0146 - val_accuracy: 0.8384\n","Epoch 41/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6905 - accuracy: 0.9892 - val_loss: 1.0098 - val_accuracy: 0.8466\n","Epoch 42/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6891 - accuracy: 0.9900 - val_loss: 1.0246 - val_accuracy: 0.8521\n","Epoch 43/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6876 - accuracy: 0.9904 - val_loss: 1.0107 - val_accuracy: 0.8521\n","Epoch 44/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.6841 - accuracy: 0.9917 - val_loss: 1.0059 - val_accuracy: 0.8575\n","Epoch 45/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6852 - accuracy: 0.9904 - val_loss: 1.0092 - val_accuracy: 0.8521\n","Epoch 46/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6837 - accuracy: 0.9912 - val_loss: 1.0057 - val_accuracy: 0.8548\n","Epoch 47/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.6829 - accuracy: 0.9924 - val_loss: 1.0122 - val_accuracy: 0.8603\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6801 - accuracy: 0.9927 - val_loss: 0.9981 - val_accuracy: 0.8521\n","Epoch 49/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6812 - accuracy: 0.9924 - val_loss: 1.0131 - val_accuracy: 0.8438\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6791 - accuracy: 0.9917 - val_loss: 1.0141 - val_accuracy: 0.8466\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6787 - accuracy: 0.9924 - val_loss: 1.0006 - val_accuracy: 0.8493\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6752 - accuracy: 0.9936 - val_loss: 1.0154 - val_accuracy: 0.8438\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6749 - accuracy: 0.9932 - val_loss: 1.0260 - val_accuracy: 0.8466\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6746 - accuracy: 0.9934 - val_loss: 1.0205 - val_accuracy: 0.8493\n","Epoch 55/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6722 - accuracy: 0.9935 - val_loss: 1.0046 - val_accuracy: 0.8466\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6696 - accuracy: 0.9947 - val_loss: 1.0066 - val_accuracy: 0.8493\n","Epoch 57/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6690 - accuracy: 0.9951 - val_loss: 1.0072 - val_accuracy: 0.8521\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6686 - accuracy: 0.9955 - val_loss: 1.0049 - val_accuracy: 0.8548\n","Epoch 59/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6679 - accuracy: 0.9951 - val_loss: 1.0042 - val_accuracy: 0.8548\n","Epoch 60/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6681 - accuracy: 0.9956 - val_loss: 1.0060 - val_accuracy: 0.8466\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6669 - accuracy: 0.9954 - val_loss: 1.0074 - val_accuracy: 0.8521\n","Epoch 62/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6674 - accuracy: 0.9948 - val_loss: 1.0103 - val_accuracy: 0.8466\n","Epoch 63/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6678 - accuracy: 0.9955 - val_loss: 1.0082 - val_accuracy: 0.8548\n","Epoch 64/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6676 - accuracy: 0.9952 - val_loss: 1.0086 - val_accuracy: 0.8521\n","Epoch 65/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6678 - accuracy: 0.9951 - val_loss: 1.0084 - val_accuracy: 0.8548\n","Epoch 66/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6676 - accuracy: 0.9949 - val_loss: 1.0080 - val_accuracy: 0.8548\n","Epoch 67/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6661 - accuracy: 0.9959 - val_loss: 1.0073 - val_accuracy: 0.8548\n","准确率得分： 0.86027\n","Processing fold: 2 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 71ms/step - loss: 2.0076 - accuracy: 0.4352 - val_loss: 1.7145 - val_accuracy: 0.5096\n","Epoch 2/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.6479 - accuracy: 0.5711 - val_loss: 1.5539 - val_accuracy: 0.5726\n","Epoch 3/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.4981 - accuracy: 0.6412 - val_loss: 1.5130 - val_accuracy: 0.6000\n","Epoch 4/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.4021 - accuracy: 0.6791 - val_loss: 1.3348 - val_accuracy: 0.6822\n","Epoch 5/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.3265 - accuracy: 0.7140 - val_loss: 1.2818 - val_accuracy: 0.7123\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2700 - accuracy: 0.7396 - val_loss: 1.2474 - val_accuracy: 0.7205\n","Epoch 7/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2164 - accuracy: 0.7626 - val_loss: 1.2301 - val_accuracy: 0.7370\n","Epoch 8/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1742 - accuracy: 0.7829 - val_loss: 1.2301 - val_accuracy: 0.7151\n","Epoch 9/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1444 - accuracy: 0.7951 - val_loss: 1.1531 - val_accuracy: 0.7781\n","Epoch 10/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.1070 - accuracy: 0.8137 - val_loss: 1.1663 - val_accuracy: 0.7671\n","Epoch 11/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0828 - accuracy: 0.8222 - val_loss: 1.1260 - val_accuracy: 0.7781\n","Epoch 12/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.0472 - accuracy: 0.8412 - val_loss: 1.1292 - val_accuracy: 0.7836\n","Epoch 13/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0278 - accuracy: 0.8493 - val_loss: 1.1504 - val_accuracy: 0.7836\n","Epoch 14/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.0024 - accuracy: 0.8607 - val_loss: 1.0780 - val_accuracy: 0.8000\n","Epoch 15/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.9852 - accuracy: 0.8696 - val_loss: 1.1219 - val_accuracy: 0.7753\n","Epoch 16/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9622 - accuracy: 0.8777 - val_loss: 1.0954 - val_accuracy: 0.7918\n","Epoch 17/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9438 - accuracy: 0.8851 - val_loss: 1.0665 - val_accuracy: 0.7945\n","Epoch 18/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9296 - accuracy: 0.8942 - val_loss: 1.0999 - val_accuracy: 0.7863\n","Epoch 19/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9147 - accuracy: 0.8990 - val_loss: 1.0942 - val_accuracy: 0.8000\n","Epoch 20/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8927 - accuracy: 0.9086 - val_loss: 1.0683 - val_accuracy: 0.8055\n","Epoch 21/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8821 - accuracy: 0.9137 - val_loss: 1.0373 - val_accuracy: 0.8192\n","Epoch 22/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8701 - accuracy: 0.9175 - val_loss: 1.0432 - val_accuracy: 0.8164\n","Epoch 23/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8565 - accuracy: 0.9230 - val_loss: 1.0718 - val_accuracy: 0.8055\n","Epoch 24/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.8537 - accuracy: 0.9267 - val_loss: 1.0324 - val_accuracy: 0.8274\n","Epoch 25/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.8253 - accuracy: 0.9353 - val_loss: 1.0597 - val_accuracy: 0.8137\n","Epoch 26/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8227 - accuracy: 0.9380 - val_loss: 1.0461 - val_accuracy: 0.8219\n","Epoch 27/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.8145 - accuracy: 0.9400 - val_loss: 1.0606 - val_accuracy: 0.8521\n","Epoch 28/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8108 - accuracy: 0.9436 - val_loss: 1.0532 - val_accuracy: 0.8438\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7965 - accuracy: 0.9497 - val_loss: 1.1248 - val_accuracy: 0.8055\n","Epoch 30/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7958 - accuracy: 0.9490 - val_loss: 1.0314 - val_accuracy: 0.8548\n","Epoch 31/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7788 - accuracy: 0.9551 - val_loss: 1.0725 - val_accuracy: 0.8329\n","Epoch 32/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7754 - accuracy: 0.9577 - val_loss: 1.0578 - val_accuracy: 0.8247\n","Epoch 33/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7755 - accuracy: 0.9562 - val_loss: 1.0782 - val_accuracy: 0.8274\n","Epoch 34/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7590 - accuracy: 0.9633 - val_loss: 1.1131 - val_accuracy: 0.8164\n","Epoch 35/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7680 - accuracy: 0.9597 - val_loss: 1.0648 - val_accuracy: 0.8247\n","Epoch 36/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7538 - accuracy: 0.9641 - val_loss: 1.0809 - val_accuracy: 0.8384\n","Epoch 37/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7427 - accuracy: 0.9706 - val_loss: 1.0670 - val_accuracy: 0.8247\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7423 - accuracy: 0.9672 - val_loss: 1.0963 - val_accuracy: 0.8301\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7058 - accuracy: 0.9842 - val_loss: 1.0231 - val_accuracy: 0.8466\n","Epoch 40/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6892 - accuracy: 0.9888 - val_loss: 1.0242 - val_accuracy: 0.8548\n","Epoch 41/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6843 - accuracy: 0.9904 - val_loss: 1.0134 - val_accuracy: 0.8521\n","Epoch 42/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6789 - accuracy: 0.9913 - val_loss: 1.0148 - val_accuracy: 0.8548\n","Epoch 43/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.6785 - accuracy: 0.9912 - val_loss: 1.0187 - val_accuracy: 0.8630\n","Epoch 44/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6754 - accuracy: 0.9923 - val_loss: 1.0198 - val_accuracy: 0.8493\n","Epoch 45/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6738 - accuracy: 0.9920 - val_loss: 1.0195 - val_accuracy: 0.8575\n","Epoch 46/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6716 - accuracy: 0.9933 - val_loss: 1.0081 - val_accuracy: 0.8548\n","Epoch 47/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6692 - accuracy: 0.9937 - val_loss: 1.0221 - val_accuracy: 0.8575\n","Epoch 48/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6677 - accuracy: 0.9937 - val_loss: 1.0186 - val_accuracy: 0.8466\n","Epoch 49/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6669 - accuracy: 0.9933 - val_loss: 1.0250 - val_accuracy: 0.8548\n","Epoch 50/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.6663 - accuracy: 0.9941 - val_loss: 1.0291 - val_accuracy: 0.8603\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6643 - accuracy: 0.9944 - val_loss: 1.0271 - val_accuracy: 0.8548\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6636 - accuracy: 0.9938 - val_loss: 1.0239 - val_accuracy: 0.8548\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6619 - accuracy: 0.9950 - val_loss: 1.0210 - val_accuracy: 0.8548\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6615 - accuracy: 0.9950 - val_loss: 1.0216 - val_accuracy: 0.8521\n","Epoch 55/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6615 - accuracy: 0.9951 - val_loss: 1.0217 - val_accuracy: 0.8548\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6612 - accuracy: 0.9951 - val_loss: 1.0239 - val_accuracy: 0.8575\n","Epoch 57/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6613 - accuracy: 0.9948 - val_loss: 1.0228 - val_accuracy: 0.8548\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6601 - accuracy: 0.9952 - val_loss: 1.0218 - val_accuracy: 0.8603\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6598 - accuracy: 0.9953 - val_loss: 1.0259 - val_accuracy: 0.8575\n","Epoch 60/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6600 - accuracy: 0.9957 - val_loss: 1.0257 - val_accuracy: 0.8575\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6602 - accuracy: 0.9951 - val_loss: 1.0255 - val_accuracy: 0.8575\n","Epoch 62/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6610 - accuracy: 0.9955 - val_loss: 1.0254 - val_accuracy: 0.8575\n","Epoch 63/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6595 - accuracy: 0.9955 - val_loss: 1.0252 - val_accuracy: 0.8575\n","准确率得分： 0.86301\n","Processing fold: 3 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 71ms/step - loss: 2.0069 - accuracy: 0.4324 - val_loss: 1.6822 - val_accuracy: 0.5425\n","Epoch 2/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.6555 - accuracy: 0.5667 - val_loss: 1.5524 - val_accuracy: 0.5918\n","Epoch 3/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.4918 - accuracy: 0.6414 - val_loss: 1.4636 - val_accuracy: 0.6384\n","Epoch 4/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3920 - accuracy: 0.6810 - val_loss: 1.3678 - val_accuracy: 0.6959\n","Epoch 5/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3167 - accuracy: 0.7190 - val_loss: 1.3145 - val_accuracy: 0.7178\n","Epoch 6/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.2533 - accuracy: 0.7454 - val_loss: 1.3732 - val_accuracy: 0.6767\n","Epoch 7/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2143 - accuracy: 0.7619 - val_loss: 1.2497 - val_accuracy: 0.7233\n","Epoch 8/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1670 - accuracy: 0.7831 - val_loss: 1.1837 - val_accuracy: 0.7479\n","Epoch 9/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1351 - accuracy: 0.7995 - val_loss: 1.1913 - val_accuracy: 0.7644\n","Epoch 10/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1065 - accuracy: 0.8131 - val_loss: 1.2197 - val_accuracy: 0.7589\n","Epoch 11/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0779 - accuracy: 0.8232 - val_loss: 1.1171 - val_accuracy: 0.7863\n","Epoch 12/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0485 - accuracy: 0.8385 - val_loss: 1.1776 - val_accuracy: 0.7671\n","Epoch 13/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0236 - accuracy: 0.8482 - val_loss: 1.1139 - val_accuracy: 0.7918\n","Epoch 14/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9983 - accuracy: 0.8634 - val_loss: 1.1008 - val_accuracy: 0.7918\n","Epoch 15/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9876 - accuracy: 0.8656 - val_loss: 1.0611 - val_accuracy: 0.8110\n","Epoch 16/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9584 - accuracy: 0.8804 - val_loss: 1.0797 - val_accuracy: 0.8027\n","Epoch 17/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.9458 - accuracy: 0.8836 - val_loss: 1.0525 - val_accuracy: 0.8137\n","Epoch 18/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9300 - accuracy: 0.8912 - val_loss: 1.0745 - val_accuracy: 0.8219\n","Epoch 19/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9148 - accuracy: 0.8992 - val_loss: 1.0958 - val_accuracy: 0.8055\n","Epoch 20/500\n","273/273 [==============================] - 18s 66ms/step - loss: 0.8994 - accuracy: 0.9051 - val_loss: 1.0456 - val_accuracy: 0.8192\n","Epoch 21/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.8821 - accuracy: 0.9146 - val_loss: 0.9889 - val_accuracy: 0.8548\n","Epoch 22/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8692 - accuracy: 0.9164 - val_loss: 1.0472 - val_accuracy: 0.8137\n","Epoch 23/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8500 - accuracy: 0.9240 - val_loss: 1.0493 - val_accuracy: 0.8164\n","Epoch 24/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8420 - accuracy: 0.9302 - val_loss: 1.0436 - val_accuracy: 0.8329\n","Epoch 25/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8277 - accuracy: 0.9359 - val_loss: 1.0869 - val_accuracy: 0.8219\n","Epoch 26/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8241 - accuracy: 0.9369 - val_loss: 1.0184 - val_accuracy: 0.8438\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8152 - accuracy: 0.9408 - val_loss: 1.0308 - val_accuracy: 0.8219\n","Epoch 28/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8091 - accuracy: 0.9433 - val_loss: 1.0431 - val_accuracy: 0.8192\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7917 - accuracy: 0.9508 - val_loss: 1.0342 - val_accuracy: 0.8329\n","Epoch 30/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7427 - accuracy: 0.9714 - val_loss: 0.9619 - val_accuracy: 0.8438\n","Epoch 31/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.7251 - accuracy: 0.9784 - val_loss: 0.9348 - val_accuracy: 0.8603\n","Epoch 32/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7175 - accuracy: 0.9804 - val_loss: 0.9510 - val_accuracy: 0.8658\n","Epoch 33/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7157 - accuracy: 0.9820 - val_loss: 0.9506 - val_accuracy: 0.8603\n","Epoch 34/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.7089 - accuracy: 0.9838 - val_loss: 0.9540 - val_accuracy: 0.8685\n","Epoch 35/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7064 - accuracy: 0.9834 - val_loss: 0.9534 - val_accuracy: 0.8630\n","Epoch 36/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7044 - accuracy: 0.9846 - val_loss: 0.9429 - val_accuracy: 0.8548\n","Epoch 37/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7029 - accuracy: 0.9861 - val_loss: 0.9420 - val_accuracy: 0.8767\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7000 - accuracy: 0.9876 - val_loss: 0.9454 - val_accuracy: 0.8630\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6976 - accuracy: 0.9874 - val_loss: 0.9565 - val_accuracy: 0.8630\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6961 - accuracy: 0.9881 - val_loss: 0.9527 - val_accuracy: 0.8603\n","Epoch 41/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6932 - accuracy: 0.9880 - val_loss: 0.9349 - val_accuracy: 0.8658\n","Epoch 42/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6926 - accuracy: 0.9887 - val_loss: 0.9507 - val_accuracy: 0.8630\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6927 - accuracy: 0.9881 - val_loss: 0.9386 - val_accuracy: 0.8575\n","Epoch 44/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6893 - accuracy: 0.9891 - val_loss: 0.9530 - val_accuracy: 0.8630\n","Epoch 45/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6872 - accuracy: 0.9904 - val_loss: 0.9412 - val_accuracy: 0.8630\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6837 - accuracy: 0.9909 - val_loss: 0.9471 - val_accuracy: 0.8658\n","Epoch 47/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6826 - accuracy: 0.9924 - val_loss: 0.9499 - val_accuracy: 0.8658\n","Epoch 48/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6844 - accuracy: 0.9915 - val_loss: 0.9477 - val_accuracy: 0.8658\n","Epoch 49/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6825 - accuracy: 0.9919 - val_loss: 0.9476 - val_accuracy: 0.8630\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6821 - accuracy: 0.9919 - val_loss: 0.9505 - val_accuracy: 0.8658\n","Epoch 51/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6804 - accuracy: 0.9923 - val_loss: 0.9520 - val_accuracy: 0.8658\n","Epoch 52/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6806 - accuracy: 0.9926 - val_loss: 0.9534 - val_accuracy: 0.8658\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6806 - accuracy: 0.9913 - val_loss: 0.9547 - val_accuracy: 0.8658\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6796 - accuracy: 0.9919 - val_loss: 0.9542 - val_accuracy: 0.8658\n","Epoch 55/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6791 - accuracy: 0.9930 - val_loss: 0.9542 - val_accuracy: 0.8658\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6796 - accuracy: 0.9929 - val_loss: 0.9541 - val_accuracy: 0.8658\n","Epoch 57/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6805 - accuracy: 0.9924 - val_loss: 0.9543 - val_accuracy: 0.8658\n","准确率得分： 0.87671\n","Processing fold: 4 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 71ms/step - loss: 2.0140 - accuracy: 0.4313 - val_loss: 1.7154 - val_accuracy: 0.5452\n","Epoch 2/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.6465 - accuracy: 0.5736 - val_loss: 1.5900 - val_accuracy: 0.5616\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.4931 - accuracy: 0.6367 - val_loss: 1.4839 - val_accuracy: 0.6384\n","Epoch 4/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.3852 - accuracy: 0.6842 - val_loss: 1.3906 - val_accuracy: 0.6466\n","Epoch 5/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3175 - accuracy: 0.7169 - val_loss: 1.3312 - val_accuracy: 0.6740\n","Epoch 6/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2535 - accuracy: 0.7435 - val_loss: 1.3408 - val_accuracy: 0.6904\n","Epoch 7/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2034 - accuracy: 0.7701 - val_loss: 1.3027 - val_accuracy: 0.6932\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1636 - accuracy: 0.7863 - val_loss: 1.2699 - val_accuracy: 0.7014\n","Epoch 9/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.1316 - accuracy: 0.7999 - val_loss: 1.2141 - val_accuracy: 0.7260\n","Epoch 10/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0957 - accuracy: 0.8183 - val_loss: 1.1846 - val_accuracy: 0.7370\n","Epoch 11/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0707 - accuracy: 0.8286 - val_loss: 1.1749 - val_accuracy: 0.7616\n","Epoch 12/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0383 - accuracy: 0.8415 - val_loss: 1.2081 - val_accuracy: 0.7479\n","Epoch 13/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.0201 - accuracy: 0.8516 - val_loss: 1.1320 - val_accuracy: 0.7890\n","Epoch 14/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9923 - accuracy: 0.8626 - val_loss: 1.1330 - val_accuracy: 0.7945\n","Epoch 15/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9659 - accuracy: 0.8733 - val_loss: 1.1593 - val_accuracy: 0.7699\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9494 - accuracy: 0.8822 - val_loss: 1.1341 - val_accuracy: 0.7808\n","Epoch 17/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9282 - accuracy: 0.8912 - val_loss: 1.0903 - val_accuracy: 0.7918\n","Epoch 18/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9098 - accuracy: 0.8999 - val_loss: 1.1227 - val_accuracy: 0.7808\n","Epoch 19/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8940 - accuracy: 0.9087 - val_loss: 1.0941 - val_accuracy: 0.8164\n","Epoch 20/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8814 - accuracy: 0.9127 - val_loss: 1.1238 - val_accuracy: 0.7616\n","Epoch 21/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8713 - accuracy: 0.9169 - val_loss: 1.1235 - val_accuracy: 0.7863\n","Epoch 22/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.8615 - accuracy: 0.9193 - val_loss: 1.0703 - val_accuracy: 0.8247\n","Epoch 23/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8350 - accuracy: 0.9326 - val_loss: 1.0872 - val_accuracy: 0.8192\n","Epoch 24/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8295 - accuracy: 0.9357 - val_loss: 1.1208 - val_accuracy: 0.7726\n","Epoch 25/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8256 - accuracy: 0.9358 - val_loss: 1.0744 - val_accuracy: 0.8055\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8148 - accuracy: 0.9404 - val_loss: 1.0813 - val_accuracy: 0.8110\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8006 - accuracy: 0.9485 - val_loss: 1.0996 - val_accuracy: 0.8000\n","Epoch 28/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7919 - accuracy: 0.9532 - val_loss: 1.0832 - val_accuracy: 0.7945\n","Epoch 29/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7835 - accuracy: 0.9537 - val_loss: 1.0679 - val_accuracy: 0.8164\n","Epoch 30/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7767 - accuracy: 0.9569 - val_loss: 1.0862 - val_accuracy: 0.8164\n","Epoch 31/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7257 - accuracy: 0.9777 - val_loss: 1.0194 - val_accuracy: 0.8137\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7100 - accuracy: 0.9847 - val_loss: 1.0111 - val_accuracy: 0.8192\n","Epoch 33/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7054 - accuracy: 0.9853 - val_loss: 1.0246 - val_accuracy: 0.8219\n","Epoch 34/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7010 - accuracy: 0.9867 - val_loss: 1.0247 - val_accuracy: 0.8219\n","Epoch 35/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6988 - accuracy: 0.9873 - val_loss: 1.0198 - val_accuracy: 0.8137\n","Epoch 36/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6955 - accuracy: 0.9878 - val_loss: 1.0149 - val_accuracy: 0.8274\n","Epoch 37/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6941 - accuracy: 0.9877 - val_loss: 1.0109 - val_accuracy: 0.8274\n","Epoch 38/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6925 - accuracy: 0.9882 - val_loss: 1.0045 - val_accuracy: 0.8301\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6896 - accuracy: 0.9899 - val_loss: 1.0227 - val_accuracy: 0.8192\n","Epoch 40/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6881 - accuracy: 0.9905 - val_loss: 1.0076 - val_accuracy: 0.8274\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6852 - accuracy: 0.9913 - val_loss: 1.0302 - val_accuracy: 0.8137\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6855 - accuracy: 0.9911 - val_loss: 1.0194 - val_accuracy: 0.8247\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6831 - accuracy: 0.9905 - val_loss: 1.0260 - val_accuracy: 0.8247\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6819 - accuracy: 0.9905 - val_loss: 1.0218 - val_accuracy: 0.8219\n","Epoch 45/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6806 - accuracy: 0.9913 - val_loss: 1.0213 - val_accuracy: 0.8164\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6780 - accuracy: 0.9923 - val_loss: 1.0324 - val_accuracy: 0.8164\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6764 - accuracy: 0.9929 - val_loss: 1.0163 - val_accuracy: 0.8192\n","Epoch 48/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6736 - accuracy: 0.9928 - val_loss: 1.0176 - val_accuracy: 0.8192\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6740 - accuracy: 0.9936 - val_loss: 1.0157 - val_accuracy: 0.8247\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6750 - accuracy: 0.9933 - val_loss: 1.0137 - val_accuracy: 0.8301\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6740 - accuracy: 0.9933 - val_loss: 1.0157 - val_accuracy: 0.8274\n","Epoch 52/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6740 - accuracy: 0.9939 - val_loss: 1.0160 - val_accuracy: 0.8329\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6750 - accuracy: 0.9933 - val_loss: 1.0151 - val_accuracy: 0.8301\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6737 - accuracy: 0.9933 - val_loss: 1.0196 - val_accuracy: 0.8219\n","Epoch 55/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6727 - accuracy: 0.9932 - val_loss: 1.0177 - val_accuracy: 0.8219\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6735 - accuracy: 0.9935 - val_loss: 1.0214 - val_accuracy: 0.8274\n","Epoch 57/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6721 - accuracy: 0.9940 - val_loss: 1.0214 - val_accuracy: 0.8247\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6730 - accuracy: 0.9929 - val_loss: 1.0251 - val_accuracy: 0.8247\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6729 - accuracy: 0.9938 - val_loss: 1.0226 - val_accuracy: 0.8247\n","Epoch 60/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6738 - accuracy: 0.9927 - val_loss: 1.0229 - val_accuracy: 0.8247\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6722 - accuracy: 0.9939 - val_loss: 1.0224 - val_accuracy: 0.8247\n","Epoch 62/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6703 - accuracy: 0.9940 - val_loss: 1.0226 - val_accuracy: 0.8247\n","Epoch 63/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6720 - accuracy: 0.9940 - val_loss: 1.0230 - val_accuracy: 0.8247\n","Epoch 64/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6717 - accuracy: 0.9936 - val_loss: 1.0233 - val_accuracy: 0.8247\n","Epoch 65/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6722 - accuracy: 0.9933 - val_loss: 1.0232 - val_accuracy: 0.8247\n","Epoch 66/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6700 - accuracy: 0.9947 - val_loss: 1.0229 - val_accuracy: 0.8247\n","Epoch 67/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6702 - accuracy: 0.9943 - val_loss: 1.0230 - val_accuracy: 0.8247\n","Epoch 68/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6716 - accuracy: 0.9941 - val_loss: 1.0223 - val_accuracy: 0.8247\n","Epoch 69/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6710 - accuracy: 0.9944 - val_loss: 1.0224 - val_accuracy: 0.8247\n","Epoch 70/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6716 - accuracy: 0.9941 - val_loss: 1.0224 - val_accuracy: 0.8247\n","Epoch 71/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6719 - accuracy: 0.9941 - val_loss: 1.0223 - val_accuracy: 0.8247\n","Epoch 72/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6716 - accuracy: 0.9946 - val_loss: 1.0224 - val_accuracy: 0.8247\n","准确率得分： 0.83288\n","Processing fold: 5 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0112 - accuracy: 0.4315 - val_loss: 1.7951 - val_accuracy: 0.4932\n","Epoch 2/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.6616 - accuracy: 0.5685 - val_loss: 1.6633 - val_accuracy: 0.5123\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.4987 - accuracy: 0.6374 - val_loss: 1.5050 - val_accuracy: 0.6137\n","Epoch 4/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.4004 - accuracy: 0.6757 - val_loss: 1.4416 - val_accuracy: 0.6603\n","Epoch 5/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.3231 - accuracy: 0.7169 - val_loss: 1.4134 - val_accuracy: 0.6438\n","Epoch 6/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2626 - accuracy: 0.7416 - val_loss: 1.3219 - val_accuracy: 0.6904\n","Epoch 7/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2074 - accuracy: 0.7670 - val_loss: 1.2794 - val_accuracy: 0.7233\n","Epoch 8/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.1630 - accuracy: 0.7881 - val_loss: 1.2206 - val_accuracy: 0.7507\n","Epoch 9/500\n","273/273 [==============================] - 18s 66ms/step - loss: 1.1255 - accuracy: 0.8049 - val_loss: 1.2198 - val_accuracy: 0.7342\n","Epoch 10/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0919 - accuracy: 0.8158 - val_loss: 1.2035 - val_accuracy: 0.7397\n","Epoch 11/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0663 - accuracy: 0.8282 - val_loss: 1.1884 - val_accuracy: 0.7671\n","Epoch 12/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0339 - accuracy: 0.8467 - val_loss: 1.1538 - val_accuracy: 0.7753\n","Epoch 13/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0073 - accuracy: 0.8552 - val_loss: 1.1391 - val_accuracy: 0.7890\n","Epoch 14/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9889 - accuracy: 0.8656 - val_loss: 1.1117 - val_accuracy: 0.7863\n","Epoch 15/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9685 - accuracy: 0.8759 - val_loss: 1.1194 - val_accuracy: 0.8055\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9479 - accuracy: 0.8851 - val_loss: 1.1641 - val_accuracy: 0.7918\n","Epoch 17/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9352 - accuracy: 0.8892 - val_loss: 1.0973 - val_accuracy: 0.7945\n","Epoch 18/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9113 - accuracy: 0.8983 - val_loss: 1.0879 - val_accuracy: 0.8027\n","Epoch 19/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8917 - accuracy: 0.9097 - val_loss: 1.0737 - val_accuracy: 0.8192\n","Epoch 20/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.8797 - accuracy: 0.9138 - val_loss: 1.0375 - val_accuracy: 0.8301\n","Epoch 21/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8656 - accuracy: 0.9192 - val_loss: 1.0638 - val_accuracy: 0.8192\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8508 - accuracy: 0.9272 - val_loss: 1.0673 - val_accuracy: 0.8192\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8404 - accuracy: 0.9308 - val_loss: 1.0611 - val_accuracy: 0.8247\n","Epoch 24/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8267 - accuracy: 0.9370 - val_loss: 1.0671 - val_accuracy: 0.8082\n","Epoch 25/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8211 - accuracy: 0.9397 - val_loss: 1.0553 - val_accuracy: 0.8301\n","Epoch 26/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8151 - accuracy: 0.9418 - val_loss: 1.0448 - val_accuracy: 0.8164\n","Epoch 27/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8102 - accuracy: 0.9450 - val_loss: 1.1045 - val_accuracy: 0.8082\n","Epoch 28/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7997 - accuracy: 0.9471 - val_loss: 1.0957 - val_accuracy: 0.8082\n","Epoch 29/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7431 - accuracy: 0.9720 - val_loss: 0.9945 - val_accuracy: 0.8384\n","Epoch 30/500\n","273/273 [==============================] - 19s 71ms/step - loss: 0.7268 - accuracy: 0.9791 - val_loss: 0.9998 - val_accuracy: 0.8411\n","Epoch 31/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7186 - accuracy: 0.9814 - val_loss: 0.9923 - val_accuracy: 0.8438\n","Epoch 32/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7161 - accuracy: 0.9831 - val_loss: 0.9906 - val_accuracy: 0.8466\n","Epoch 33/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7114 - accuracy: 0.9830 - val_loss: 0.9930 - val_accuracy: 0.8575\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7078 - accuracy: 0.9861 - val_loss: 0.9979 - val_accuracy: 0.8438\n","Epoch 35/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7043 - accuracy: 0.9869 - val_loss: 1.0010 - val_accuracy: 0.8411\n","Epoch 36/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7018 - accuracy: 0.9862 - val_loss: 1.0022 - val_accuracy: 0.8384\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7016 - accuracy: 0.9861 - val_loss: 0.9865 - val_accuracy: 0.8438\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6980 - accuracy: 0.9871 - val_loss: 1.0045 - val_accuracy: 0.8411\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6976 - accuracy: 0.9871 - val_loss: 0.9896 - val_accuracy: 0.8493\n","Epoch 40/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6948 - accuracy: 0.9880 - val_loss: 0.9890 - val_accuracy: 0.8658\n","Epoch 41/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6928 - accuracy: 0.9900 - val_loss: 1.0079 - val_accuracy: 0.8493\n","Epoch 42/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6910 - accuracy: 0.9896 - val_loss: 0.9996 - val_accuracy: 0.8493\n","Epoch 43/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6892 - accuracy: 0.9908 - val_loss: 1.0030 - val_accuracy: 0.8521\n","Epoch 44/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6868 - accuracy: 0.9910 - val_loss: 0.9994 - val_accuracy: 0.8521\n","Epoch 45/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6870 - accuracy: 0.9906 - val_loss: 1.0125 - val_accuracy: 0.8521\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6865 - accuracy: 0.9905 - val_loss: 0.9997 - val_accuracy: 0.8521\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6832 - accuracy: 0.9917 - val_loss: 0.9985 - val_accuracy: 0.8575\n","Epoch 48/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6828 - accuracy: 0.9921 - val_loss: 0.9828 - val_accuracy: 0.8521\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6779 - accuracy: 0.9934 - val_loss: 0.9875 - val_accuracy: 0.8575\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6764 - accuracy: 0.9934 - val_loss: 0.9857 - val_accuracy: 0.8575\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6765 - accuracy: 0.9928 - val_loss: 0.9850 - val_accuracy: 0.8630\n","Epoch 52/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6766 - accuracy: 0.9941 - val_loss: 0.9857 - val_accuracy: 0.8685\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6775 - accuracy: 0.9930 - val_loss: 0.9897 - val_accuracy: 0.8658\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6780 - accuracy: 0.9931 - val_loss: 0.9866 - val_accuracy: 0.8575\n","Epoch 55/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6763 - accuracy: 0.9943 - val_loss: 0.9861 - val_accuracy: 0.8575\n","Epoch 56/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6755 - accuracy: 0.9940 - val_loss: 0.9894 - val_accuracy: 0.8603\n","Epoch 57/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6751 - accuracy: 0.9938 - val_loss: 0.9900 - val_accuracy: 0.8548\n","Epoch 58/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6748 - accuracy: 0.9941 - val_loss: 0.9914 - val_accuracy: 0.8575\n","Epoch 59/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6769 - accuracy: 0.9929 - val_loss: 0.9915 - val_accuracy: 0.8575\n","Epoch 60/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6761 - accuracy: 0.9928 - val_loss: 0.9917 - val_accuracy: 0.8575\n","Epoch 61/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6751 - accuracy: 0.9941 - val_loss: 0.9914 - val_accuracy: 0.8575\n","Epoch 62/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6749 - accuracy: 0.9928 - val_loss: 0.9911 - val_accuracy: 0.8575\n","Epoch 63/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6754 - accuracy: 0.9939 - val_loss: 0.9913 - val_accuracy: 0.8575\n","Epoch 64/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6760 - accuracy: 0.9933 - val_loss: 0.9916 - val_accuracy: 0.8575\n","Epoch 65/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6747 - accuracy: 0.9937 - val_loss: 0.9908 - val_accuracy: 0.8575\n","Epoch 66/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6735 - accuracy: 0.9940 - val_loss: 0.9908 - val_accuracy: 0.8575\n","Epoch 67/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6755 - accuracy: 0.9932 - val_loss: 0.9908 - val_accuracy: 0.8575\n","Epoch 68/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6757 - accuracy: 0.9931 - val_loss: 0.9909 - val_accuracy: 0.8575\n","Epoch 69/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6751 - accuracy: 0.9937 - val_loss: 0.9909 - val_accuracy: 0.8575\n","Epoch 70/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6739 - accuracy: 0.9948 - val_loss: 0.9909 - val_accuracy: 0.8575\n","Epoch 71/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6736 - accuracy: 0.9942 - val_loss: 0.9909 - val_accuracy: 0.8575\n","Epoch 72/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6739 - accuracy: 0.9937 - val_loss: 0.9909 - val_accuracy: 0.8575\n","准确率得分： 0.86849\n","Processing fold: 6 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0181 - accuracy: 0.4320 - val_loss: 1.7218 - val_accuracy: 0.5260\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6542 - accuracy: 0.5665 - val_loss: 1.5341 - val_accuracy: 0.6027\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.5014 - accuracy: 0.6373 - val_loss: 1.4702 - val_accuracy: 0.6767\n","Epoch 4/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.4005 - accuracy: 0.6811 - val_loss: 1.3263 - val_accuracy: 0.6986\n","Epoch 5/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.3215 - accuracy: 0.7185 - val_loss: 1.3834 - val_accuracy: 0.6795\n","Epoch 6/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2653 - accuracy: 0.7452 - val_loss: 1.2902 - val_accuracy: 0.7041\n","Epoch 7/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2156 - accuracy: 0.7632 - val_loss: 1.2175 - val_accuracy: 0.7507\n","Epoch 8/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1683 - accuracy: 0.7840 - val_loss: 1.1855 - val_accuracy: 0.7534\n","Epoch 9/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1339 - accuracy: 0.8011 - val_loss: 1.2135 - val_accuracy: 0.7644\n","Epoch 10/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0975 - accuracy: 0.8191 - val_loss: 1.1519 - val_accuracy: 0.7863\n","Epoch 11/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0773 - accuracy: 0.8275 - val_loss: 1.2336 - val_accuracy: 0.7479\n","Epoch 12/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0443 - accuracy: 0.8415 - val_loss: 1.1432 - val_accuracy: 0.7890\n","Epoch 13/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0168 - accuracy: 0.8488 - val_loss: 1.1829 - val_accuracy: 0.8055\n","Epoch 14/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0081 - accuracy: 0.8599 - val_loss: 1.1529 - val_accuracy: 0.8110\n","Epoch 15/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9742 - accuracy: 0.8732 - val_loss: 1.1296 - val_accuracy: 0.8027\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9576 - accuracy: 0.8810 - val_loss: 1.1021 - val_accuracy: 0.7836\n","Epoch 17/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9352 - accuracy: 0.8908 - val_loss: 1.0729 - val_accuracy: 0.8137\n","Epoch 18/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9180 - accuracy: 0.8978 - val_loss: 1.0727 - val_accuracy: 0.8219\n","Epoch 19/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9073 - accuracy: 0.9029 - val_loss: 1.1164 - val_accuracy: 0.8164\n","Epoch 20/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8945 - accuracy: 0.9073 - val_loss: 1.0841 - val_accuracy: 0.8192\n","Epoch 21/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.8847 - accuracy: 0.9103 - val_loss: 1.0806 - val_accuracy: 0.8301\n","Epoch 22/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8655 - accuracy: 0.9223 - val_loss: 1.0394 - val_accuracy: 0.8384\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8470 - accuracy: 0.9297 - val_loss: 1.0524 - val_accuracy: 0.8329\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8434 - accuracy: 0.9308 - val_loss: 1.0732 - val_accuracy: 0.8356\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8341 - accuracy: 0.9341 - val_loss: 1.0937 - val_accuracy: 0.8082\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8273 - accuracy: 0.9387 - val_loss: 1.1196 - val_accuracy: 0.8274\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8163 - accuracy: 0.9438 - val_loss: 1.0638 - val_accuracy: 0.8329\n","Epoch 28/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8053 - accuracy: 0.9459 - val_loss: 1.0431 - val_accuracy: 0.8438\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7884 - accuracy: 0.9526 - val_loss: 1.0904 - val_accuracy: 0.8247\n","Epoch 30/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.7836 - accuracy: 0.9550 - val_loss: 1.0411 - val_accuracy: 0.8466\n","Epoch 31/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7785 - accuracy: 0.9551 - val_loss: 1.0767 - val_accuracy: 0.8137\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7786 - accuracy: 0.9574 - val_loss: 1.0359 - val_accuracy: 0.8466\n","Epoch 33/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7694 - accuracy: 0.9600 - val_loss: 1.0535 - val_accuracy: 0.8493\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7614 - accuracy: 0.9634 - val_loss: 1.0517 - val_accuracy: 0.8493\n","Epoch 35/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7589 - accuracy: 0.9649 - val_loss: 1.1257 - val_accuracy: 0.8192\n","Epoch 36/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7517 - accuracy: 0.9660 - val_loss: 1.0675 - val_accuracy: 0.8329\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7530 - accuracy: 0.9660 - val_loss: 1.0923 - val_accuracy: 0.8329\n","Epoch 38/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7520 - accuracy: 0.9663 - val_loss: 1.0274 - val_accuracy: 0.8575\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7370 - accuracy: 0.9722 - val_loss: 1.0674 - val_accuracy: 0.8466\n","Epoch 40/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7371 - accuracy: 0.9711 - val_loss: 1.0473 - val_accuracy: 0.8356\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7298 - accuracy: 0.9725 - val_loss: 1.0467 - val_accuracy: 0.8521\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7284 - accuracy: 0.9742 - val_loss: 1.0542 - val_accuracy: 0.8466\n","Epoch 43/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7322 - accuracy: 0.9715 - val_loss: 1.0614 - val_accuracy: 0.8384\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7265 - accuracy: 0.9734 - val_loss: 1.0616 - val_accuracy: 0.8521\n","Epoch 45/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7253 - accuracy: 0.9752 - val_loss: 1.0004 - val_accuracy: 0.8575\n","Epoch 46/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7144 - accuracy: 0.9788 - val_loss: 1.0496 - val_accuracy: 0.8466\n","Epoch 47/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6793 - accuracy: 0.9909 - val_loss: 0.9967 - val_accuracy: 0.8685\n","Epoch 48/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6717 - accuracy: 0.9927 - val_loss: 0.9962 - val_accuracy: 0.8740\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6669 - accuracy: 0.9935 - val_loss: 0.9995 - val_accuracy: 0.8685\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6656 - accuracy: 0.9937 - val_loss: 0.9908 - val_accuracy: 0.8740\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6615 - accuracy: 0.9948 - val_loss: 1.0009 - val_accuracy: 0.8712\n","Epoch 52/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6605 - accuracy: 0.9944 - val_loss: 0.9998 - val_accuracy: 0.8740\n","Epoch 53/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6579 - accuracy: 0.9956 - val_loss: 0.9954 - val_accuracy: 0.8740\n","Epoch 54/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6579 - accuracy: 0.9955 - val_loss: 1.0049 - val_accuracy: 0.8712\n","Epoch 55/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6575 - accuracy: 0.9945 - val_loss: 0.9938 - val_accuracy: 0.8740\n","Epoch 56/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6576 - accuracy: 0.9955 - val_loss: 0.9982 - val_accuracy: 0.8712\n","Epoch 57/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6535 - accuracy: 0.9966 - val_loss: 0.9969 - val_accuracy: 0.8712\n","Epoch 58/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6538 - accuracy: 0.9957 - val_loss: 0.9967 - val_accuracy: 0.8712\n","Epoch 59/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6528 - accuracy: 0.9960 - val_loss: 0.9958 - val_accuracy: 0.8712\n","Epoch 60/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6534 - accuracy: 0.9961 - val_loss: 0.9951 - val_accuracy: 0.8685\n","Epoch 61/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6526 - accuracy: 0.9964 - val_loss: 0.9968 - val_accuracy: 0.8712\n","Epoch 62/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6521 - accuracy: 0.9961 - val_loss: 0.9975 - val_accuracy: 0.8685\n","Epoch 63/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6526 - accuracy: 0.9963 - val_loss: 0.9990 - val_accuracy: 0.8712\n","Epoch 64/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6518 - accuracy: 0.9964 - val_loss: 0.9986 - val_accuracy: 0.8712\n","Epoch 65/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6517 - accuracy: 0.9963 - val_loss: 0.9985 - val_accuracy: 0.8712\n","Epoch 66/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6520 - accuracy: 0.9969 - val_loss: 0.9984 - val_accuracy: 0.8712\n","Epoch 67/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6504 - accuracy: 0.9960 - val_loss: 0.9981 - val_accuracy: 0.8712\n","Epoch 68/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6512 - accuracy: 0.9964 - val_loss: 0.9980 - val_accuracy: 0.8712\n","准确率得分： 0.87397\n","Processing fold: 7 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.9950 - accuracy: 0.4401 - val_loss: 1.6898 - val_accuracy: 0.5425\n","Epoch 2/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.6406 - accuracy: 0.5738 - val_loss: 1.4980 - val_accuracy: 0.6055\n","Epoch 3/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.4792 - accuracy: 0.6397 - val_loss: 1.4973 - val_accuracy: 0.6137\n","Epoch 4/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3848 - accuracy: 0.6865 - val_loss: 1.3259 - val_accuracy: 0.6986\n","Epoch 5/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.3118 - accuracy: 0.7217 - val_loss: 1.3292 - val_accuracy: 0.7041\n","Epoch 6/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2570 - accuracy: 0.7452 - val_loss: 1.2853 - val_accuracy: 0.7151\n","Epoch 7/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2176 - accuracy: 0.7637 - val_loss: 1.2019 - val_accuracy: 0.7315\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1720 - accuracy: 0.7835 - val_loss: 1.2141 - val_accuracy: 0.7342\n","Epoch 9/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1372 - accuracy: 0.8000 - val_loss: 1.1394 - val_accuracy: 0.7644\n","Epoch 10/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1079 - accuracy: 0.8148 - val_loss: 1.1566 - val_accuracy: 0.7863\n","Epoch 11/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0725 - accuracy: 0.8281 - val_loss: 1.1358 - val_accuracy: 0.7836\n","Epoch 12/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0489 - accuracy: 0.8403 - val_loss: 1.1295 - val_accuracy: 0.7753\n","Epoch 13/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0249 - accuracy: 0.8517 - val_loss: 1.0860 - val_accuracy: 0.8055\n","Epoch 14/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9984 - accuracy: 0.8640 - val_loss: 1.1207 - val_accuracy: 0.7890\n","Epoch 15/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9804 - accuracy: 0.8721 - val_loss: 1.0579 - val_accuracy: 0.8027\n","Epoch 16/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9578 - accuracy: 0.8831 - val_loss: 1.0587 - val_accuracy: 0.8000\n","Epoch 17/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9411 - accuracy: 0.8890 - val_loss: 1.0818 - val_accuracy: 0.8000\n","Epoch 18/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.9242 - accuracy: 0.8953 - val_loss: 1.0404 - val_accuracy: 0.8274\n","Epoch 19/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9116 - accuracy: 0.9039 - val_loss: 1.0504 - val_accuracy: 0.8055\n","Epoch 20/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8902 - accuracy: 0.9124 - val_loss: 1.0504 - val_accuracy: 0.8301\n","Epoch 21/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8784 - accuracy: 0.9167 - val_loss: 1.0921 - val_accuracy: 0.8027\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8650 - accuracy: 0.9220 - val_loss: 1.0485 - val_accuracy: 0.8137\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8515 - accuracy: 0.9277 - val_loss: 1.0622 - val_accuracy: 0.8164\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8425 - accuracy: 0.9304 - val_loss: 1.0608 - val_accuracy: 0.8247\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8411 - accuracy: 0.9337 - val_loss: 1.0432 - val_accuracy: 0.8192\n","Epoch 26/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.8171 - accuracy: 0.9420 - val_loss: 1.0510 - val_accuracy: 0.8356\n","Epoch 27/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8127 - accuracy: 0.9409 - val_loss: 1.0365 - val_accuracy: 0.8137\n","Epoch 28/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8120 - accuracy: 0.9443 - val_loss: 1.0188 - val_accuracy: 0.8411\n","Epoch 29/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7992 - accuracy: 0.9504 - val_loss: 1.0399 - val_accuracy: 0.8411\n","Epoch 30/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7927 - accuracy: 0.9528 - val_loss: 1.0506 - val_accuracy: 0.8247\n","Epoch 31/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7791 - accuracy: 0.9580 - val_loss: 1.0510 - val_accuracy: 0.8438\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7809 - accuracy: 0.9560 - val_loss: 1.0981 - val_accuracy: 0.8082\n","Epoch 33/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7705 - accuracy: 0.9604 - val_loss: 1.0395 - val_accuracy: 0.8110\n","Epoch 34/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7645 - accuracy: 0.9639 - val_loss: 1.1004 - val_accuracy: 0.8110\n","Epoch 35/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7581 - accuracy: 0.9640 - val_loss: 1.0436 - val_accuracy: 0.8329\n","Epoch 36/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7547 - accuracy: 0.9676 - val_loss: 1.0149 - val_accuracy: 0.8411\n","Epoch 37/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7489 - accuracy: 0.9676 - val_loss: 1.0485 - val_accuracy: 0.8384\n","Epoch 38/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7417 - accuracy: 0.9696 - val_loss: 1.1027 - val_accuracy: 0.8137\n","Epoch 39/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7534 - accuracy: 0.9650 - val_loss: 1.0007 - val_accuracy: 0.8438\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6983 - accuracy: 0.9866 - val_loss: 1.0002 - val_accuracy: 0.8411\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6892 - accuracy: 0.9904 - val_loss: 0.9969 - val_accuracy: 0.8384\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6836 - accuracy: 0.9921 - val_loss: 0.9987 - val_accuracy: 0.8329\n","Epoch 43/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6819 - accuracy: 0.9916 - val_loss: 1.0071 - val_accuracy: 0.8301\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6785 - accuracy: 0.9927 - val_loss: 0.9995 - val_accuracy: 0.8301\n","Epoch 45/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6764 - accuracy: 0.9927 - val_loss: 0.9953 - val_accuracy: 0.8356\n","Epoch 46/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6753 - accuracy: 0.9929 - val_loss: 1.0114 - val_accuracy: 0.8356\n","Epoch 47/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6727 - accuracy: 0.9933 - val_loss: 1.0147 - val_accuracy: 0.8192\n","Epoch 48/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6715 - accuracy: 0.9937 - val_loss: 1.0028 - val_accuracy: 0.8301\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6694 - accuracy: 0.9951 - val_loss: 1.0033 - val_accuracy: 0.8356\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6685 - accuracy: 0.9954 - val_loss: 0.9971 - val_accuracy: 0.8438\n","Epoch 51/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6682 - accuracy: 0.9943 - val_loss: 0.9994 - val_accuracy: 0.8411\n","准确率得分： 0.84384\n","Processing fold: 8 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0066 - accuracy: 0.4292 - val_loss: 1.6860 - val_accuracy: 0.5370\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6438 - accuracy: 0.5695 - val_loss: 1.4871 - val_accuracy: 0.5945\n","Epoch 3/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.4829 - accuracy: 0.6414 - val_loss: 1.3695 - val_accuracy: 0.6575\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3961 - accuracy: 0.6824 - val_loss: 1.3139 - val_accuracy: 0.6795\n","Epoch 5/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3160 - accuracy: 0.7160 - val_loss: 1.2965 - val_accuracy: 0.6877\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2562 - accuracy: 0.7474 - val_loss: 1.2432 - val_accuracy: 0.7260\n","Epoch 7/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2039 - accuracy: 0.7690 - val_loss: 1.1753 - val_accuracy: 0.7479\n","Epoch 8/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.1634 - accuracy: 0.7872 - val_loss: 1.1835 - val_accuracy: 0.7370\n","Epoch 9/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.1301 - accuracy: 0.8025 - val_loss: 1.1332 - val_accuracy: 0.7753\n","Epoch 10/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0941 - accuracy: 0.8186 - val_loss: 1.1087 - val_accuracy: 0.7863\n","Epoch 11/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0670 - accuracy: 0.8298 - val_loss: 1.1120 - val_accuracy: 0.7973\n","Epoch 12/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0365 - accuracy: 0.8443 - val_loss: 1.1134 - val_accuracy: 0.7589\n","Epoch 13/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0117 - accuracy: 0.8531 - val_loss: 1.0920 - val_accuracy: 0.7973\n","Epoch 14/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9936 - accuracy: 0.8638 - val_loss: 1.1109 - val_accuracy: 0.7644\n","Epoch 15/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9667 - accuracy: 0.8763 - val_loss: 1.0523 - val_accuracy: 0.8110\n","Epoch 16/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9555 - accuracy: 0.8796 - val_loss: 1.0665 - val_accuracy: 0.8110\n","Epoch 17/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9364 - accuracy: 0.8900 - val_loss: 1.0732 - val_accuracy: 0.8055\n","Epoch 18/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9165 - accuracy: 0.8988 - val_loss: 1.0109 - val_accuracy: 0.8411\n","Epoch 19/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8983 - accuracy: 0.9047 - val_loss: 1.0275 - val_accuracy: 0.8000\n","Epoch 20/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.8814 - accuracy: 0.9123 - val_loss: 1.0490 - val_accuracy: 0.8438\n","Epoch 21/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8750 - accuracy: 0.9163 - val_loss: 1.0144 - val_accuracy: 0.8329\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8630 - accuracy: 0.9202 - val_loss: 1.0266 - val_accuracy: 0.8274\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8488 - accuracy: 0.9267 - val_loss: 1.0370 - val_accuracy: 0.8219\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8314 - accuracy: 0.9352 - val_loss: 1.0162 - val_accuracy: 0.8219\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8169 - accuracy: 0.9411 - val_loss: 1.0797 - val_accuracy: 0.8055\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8170 - accuracy: 0.9416 - val_loss: 1.0397 - val_accuracy: 0.8000\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8069 - accuracy: 0.9418 - val_loss: 1.0571 - val_accuracy: 0.8219\n","Epoch 28/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7922 - accuracy: 0.9519 - val_loss: 0.9871 - val_accuracy: 0.8411\n","Epoch 29/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7447 - accuracy: 0.9715 - val_loss: 0.9404 - val_accuracy: 0.8548\n","Epoch 30/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7273 - accuracy: 0.9795 - val_loss: 0.9443 - val_accuracy: 0.8493\n","Epoch 31/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7207 - accuracy: 0.9792 - val_loss: 0.9369 - val_accuracy: 0.8548\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7163 - accuracy: 0.9825 - val_loss: 0.9543 - val_accuracy: 0.8548\n","Epoch 33/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7117 - accuracy: 0.9840 - val_loss: 0.9486 - val_accuracy: 0.8630\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7115 - accuracy: 0.9843 - val_loss: 0.9469 - val_accuracy: 0.8548\n","Epoch 35/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7083 - accuracy: 0.9853 - val_loss: 0.9402 - val_accuracy: 0.8521\n","Epoch 36/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7048 - accuracy: 0.9865 - val_loss: 0.9513 - val_accuracy: 0.8521\n","Epoch 37/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7016 - accuracy: 0.9862 - val_loss: 0.9450 - val_accuracy: 0.8603\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7015 - accuracy: 0.9871 - val_loss: 0.9468 - val_accuracy: 0.8548\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6988 - accuracy: 0.9879 - val_loss: 0.9520 - val_accuracy: 0.8603\n","Epoch 40/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6966 - accuracy: 0.9882 - val_loss: 0.9486 - val_accuracy: 0.8521\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6934 - accuracy: 0.9893 - val_loss: 0.9442 - val_accuracy: 0.8384\n","Epoch 42/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6915 - accuracy: 0.9900 - val_loss: 0.9454 - val_accuracy: 0.8548\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6896 - accuracy: 0.9905 - val_loss: 0.9452 - val_accuracy: 0.8548\n","Epoch 44/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6904 - accuracy: 0.9911 - val_loss: 0.9422 - val_accuracy: 0.8575\n","Epoch 45/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6879 - accuracy: 0.9911 - val_loss: 0.9407 - val_accuracy: 0.8548\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6882 - accuracy: 0.9910 - val_loss: 0.9427 - val_accuracy: 0.8548\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6886 - accuracy: 0.9896 - val_loss: 0.9459 - val_accuracy: 0.8493\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6878 - accuracy: 0.9910 - val_loss: 0.9455 - val_accuracy: 0.8548\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6875 - accuracy: 0.9919 - val_loss: 0.9405 - val_accuracy: 0.8548\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6875 - accuracy: 0.9914 - val_loss: 0.9406 - val_accuracy: 0.8548\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6885 - accuracy: 0.9909 - val_loss: 0.9410 - val_accuracy: 0.8493\n","Epoch 52/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6876 - accuracy: 0.9914 - val_loss: 0.9410 - val_accuracy: 0.8493\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6861 - accuracy: 0.9919 - val_loss: 0.9414 - val_accuracy: 0.8521\n","准确率得分： 0.86301\n","Processing fold: 9 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0072 - accuracy: 0.4326 - val_loss: 1.7098 - val_accuracy: 0.5616\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6632 - accuracy: 0.5616 - val_loss: 1.4933 - val_accuracy: 0.6219\n","Epoch 3/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.5076 - accuracy: 0.6340 - val_loss: 1.5152 - val_accuracy: 0.6164\n","Epoch 4/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.4097 - accuracy: 0.6756 - val_loss: 1.3371 - val_accuracy: 0.6959\n","Epoch 5/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.3272 - accuracy: 0.7114 - val_loss: 1.3202 - val_accuracy: 0.6932\n","Epoch 6/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2714 - accuracy: 0.7378 - val_loss: 1.3302 - val_accuracy: 0.6986\n","Epoch 7/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2195 - accuracy: 0.7595 - val_loss: 1.2617 - val_accuracy: 0.7178\n","Epoch 8/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1778 - accuracy: 0.7785 - val_loss: 1.1987 - val_accuracy: 0.7452\n","Epoch 9/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1363 - accuracy: 0.8014 - val_loss: 1.2037 - val_accuracy: 0.7562\n","Epoch 10/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1064 - accuracy: 0.8116 - val_loss: 1.1587 - val_accuracy: 0.7699\n","Epoch 11/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0774 - accuracy: 0.8264 - val_loss: 1.1245 - val_accuracy: 0.7671\n","Epoch 12/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0450 - accuracy: 0.8416 - val_loss: 1.1329 - val_accuracy: 0.7945\n","Epoch 13/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0208 - accuracy: 0.8523 - val_loss: 1.1199 - val_accuracy: 0.7863\n","Epoch 14/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9939 - accuracy: 0.8650 - val_loss: 1.0721 - val_accuracy: 0.8274\n","Epoch 15/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9746 - accuracy: 0.8735 - val_loss: 1.0861 - val_accuracy: 0.8000\n","Epoch 16/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9544 - accuracy: 0.8821 - val_loss: 1.1101 - val_accuracy: 0.7890\n","Epoch 17/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9412 - accuracy: 0.8857 - val_loss: 1.0523 - val_accuracy: 0.8055\n","Epoch 18/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9163 - accuracy: 0.8977 - val_loss: 1.0645 - val_accuracy: 0.8110\n","Epoch 19/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8991 - accuracy: 0.9058 - val_loss: 1.0607 - val_accuracy: 0.8137\n","Epoch 20/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8876 - accuracy: 0.9135 - val_loss: 1.0481 - val_accuracy: 0.8274\n","Epoch 21/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8709 - accuracy: 0.9187 - val_loss: 1.0411 - val_accuracy: 0.8192\n","Epoch 22/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8673 - accuracy: 0.9200 - val_loss: 1.0298 - val_accuracy: 0.8192\n","Epoch 23/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7966 - accuracy: 0.9531 - val_loss: 0.9842 - val_accuracy: 0.8466\n","Epoch 24/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7766 - accuracy: 0.9611 - val_loss: 0.9798 - val_accuracy: 0.8575\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7692 - accuracy: 0.9633 - val_loss: 0.9713 - val_accuracy: 0.8521\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7600 - accuracy: 0.9667 - val_loss: 0.9842 - val_accuracy: 0.8521\n","Epoch 27/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7578 - accuracy: 0.9701 - val_loss: 0.9724 - val_accuracy: 0.8630\n","Epoch 28/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7552 - accuracy: 0.9700 - val_loss: 0.9799 - val_accuracy: 0.8493\n","Epoch 29/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7476 - accuracy: 0.9711 - val_loss: 0.9677 - val_accuracy: 0.8466\n","Epoch 30/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7423 - accuracy: 0.9738 - val_loss: 0.9786 - val_accuracy: 0.8466\n","Epoch 31/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7431 - accuracy: 0.9724 - val_loss: 0.9742 - val_accuracy: 0.8493\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7404 - accuracy: 0.9739 - val_loss: 0.9710 - val_accuracy: 0.8384\n","Epoch 33/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7377 - accuracy: 0.9753 - val_loss: 0.9651 - val_accuracy: 0.8493\n","Epoch 34/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7347 - accuracy: 0.9761 - val_loss: 0.9753 - val_accuracy: 0.8575\n","Epoch 35/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7291 - accuracy: 0.9780 - val_loss: 0.9683 - val_accuracy: 0.8575\n","Epoch 36/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7250 - accuracy: 0.9808 - val_loss: 0.9636 - val_accuracy: 0.8575\n","Epoch 37/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7265 - accuracy: 0.9801 - val_loss: 0.9626 - val_accuracy: 0.8575\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7248 - accuracy: 0.9790 - val_loss: 0.9628 - val_accuracy: 0.8548\n","Epoch 39/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7218 - accuracy: 0.9813 - val_loss: 0.9626 - val_accuracy: 0.8603\n","Epoch 40/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7217 - accuracy: 0.9827 - val_loss: 0.9635 - val_accuracy: 0.8603\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7213 - accuracy: 0.9804 - val_loss: 0.9640 - val_accuracy: 0.8575\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7209 - accuracy: 0.9814 - val_loss: 0.9617 - val_accuracy: 0.8521\n","Epoch 43/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7219 - accuracy: 0.9814 - val_loss: 0.9660 - val_accuracy: 0.8548\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7234 - accuracy: 0.9811 - val_loss: 0.9654 - val_accuracy: 0.8548\n","Epoch 45/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7209 - accuracy: 0.9818 - val_loss: 0.9655 - val_accuracy: 0.8548\n","Epoch 46/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7187 - accuracy: 0.9828 - val_loss: 0.9658 - val_accuracy: 0.8548\n","Epoch 47/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7190 - accuracy: 0.9826 - val_loss: 0.9656 - val_accuracy: 0.8548\n","准确率得分： 0.86301\n","Processing fold: 10 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.9906 - accuracy: 0.4394 - val_loss: 1.6161 - val_accuracy: 0.5452\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6456 - accuracy: 0.5713 - val_loss: 1.5196 - val_accuracy: 0.5945\n","Epoch 3/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.4842 - accuracy: 0.6438 - val_loss: 1.4083 - val_accuracy: 0.6521\n","Epoch 4/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.3856 - accuracy: 0.6869 - val_loss: 1.3546 - val_accuracy: 0.6959\n","Epoch 5/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.3157 - accuracy: 0.7217 - val_loss: 1.3203 - val_accuracy: 0.6548\n","Epoch 6/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2518 - accuracy: 0.7445 - val_loss: 1.3309 - val_accuracy: 0.7014\n","Epoch 7/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2026 - accuracy: 0.7688 - val_loss: 1.2038 - val_accuracy: 0.7479\n","Epoch 8/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1562 - accuracy: 0.7915 - val_loss: 1.2286 - val_accuracy: 0.7315\n","Epoch 9/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.1252 - accuracy: 0.8092 - val_loss: 1.1975 - val_accuracy: 0.7507\n","Epoch 10/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0916 - accuracy: 0.8197 - val_loss: 1.1775 - val_accuracy: 0.7726\n","Epoch 11/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0557 - accuracy: 0.8365 - val_loss: 1.1550 - val_accuracy: 0.7753\n","Epoch 12/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0357 - accuracy: 0.8445 - val_loss: 1.1428 - val_accuracy: 0.7836\n","Epoch 13/500\n","273/273 [==============================] - 18s 66ms/step - loss: 1.0163 - accuracy: 0.8559 - val_loss: 1.1170 - val_accuracy: 0.7918\n","Epoch 14/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9830 - accuracy: 0.8662 - val_loss: 1.1850 - val_accuracy: 0.7589\n","Epoch 15/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9701 - accuracy: 0.8746 - val_loss: 1.1283 - val_accuracy: 0.7781\n","Epoch 16/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.9488 - accuracy: 0.8847 - val_loss: 1.1249 - val_accuracy: 0.8137\n","Epoch 17/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9296 - accuracy: 0.8905 - val_loss: 1.0909 - val_accuracy: 0.8055\n","Epoch 18/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9121 - accuracy: 0.8986 - val_loss: 1.0954 - val_accuracy: 0.8219\n","Epoch 19/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9001 - accuracy: 0.9054 - val_loss: 1.1318 - val_accuracy: 0.8000\n","Epoch 20/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8864 - accuracy: 0.9110 - val_loss: 1.0617 - val_accuracy: 0.7945\n","Epoch 21/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8687 - accuracy: 0.9223 - val_loss: 1.0689 - val_accuracy: 0.8192\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8575 - accuracy: 0.9213 - val_loss: 1.1075 - val_accuracy: 0.8137\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8447 - accuracy: 0.9293 - val_loss: 1.1024 - val_accuracy: 0.7863\n","Epoch 24/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8370 - accuracy: 0.9322 - val_loss: 1.1575 - val_accuracy: 0.7918\n","Epoch 25/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8199 - accuracy: 0.9400 - val_loss: 1.1322 - val_accuracy: 0.7918\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8169 - accuracy: 0.9407 - val_loss: 1.0807 - val_accuracy: 0.8137\n","Epoch 27/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7588 - accuracy: 0.9670 - val_loss: 1.0480 - val_accuracy: 0.8356\n","Epoch 28/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7416 - accuracy: 0.9739 - val_loss: 1.0400 - val_accuracy: 0.8356\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7328 - accuracy: 0.9760 - val_loss: 1.0373 - val_accuracy: 0.8247\n","Epoch 30/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7256 - accuracy: 0.9784 - val_loss: 1.0396 - val_accuracy: 0.8384\n","Epoch 31/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7247 - accuracy: 0.9805 - val_loss: 1.0363 - val_accuracy: 0.8274\n","Epoch 32/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7203 - accuracy: 0.9808 - val_loss: 1.0363 - val_accuracy: 0.8219\n","Epoch 33/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7166 - accuracy: 0.9823 - val_loss: 1.0305 - val_accuracy: 0.8329\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7158 - accuracy: 0.9826 - val_loss: 1.0373 - val_accuracy: 0.8329\n","Epoch 35/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7122 - accuracy: 0.9825 - val_loss: 1.0442 - val_accuracy: 0.8329\n","Epoch 36/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7089 - accuracy: 0.9851 - val_loss: 1.0363 - val_accuracy: 0.8384\n","Epoch 37/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7064 - accuracy: 0.9865 - val_loss: 1.0409 - val_accuracy: 0.8466\n","Epoch 38/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7047 - accuracy: 0.9861 - val_loss: 1.0402 - val_accuracy: 0.8356\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7039 - accuracy: 0.9869 - val_loss: 1.0343 - val_accuracy: 0.8356\n","Epoch 40/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7012 - accuracy: 0.9862 - val_loss: 1.0273 - val_accuracy: 0.8384\n","Epoch 41/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7018 - accuracy: 0.9865 - val_loss: 1.0397 - val_accuracy: 0.8356\n","Epoch 42/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6988 - accuracy: 0.9874 - val_loss: 1.0282 - val_accuracy: 0.8466\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6975 - accuracy: 0.9887 - val_loss: 1.0303 - val_accuracy: 0.8356\n","Epoch 44/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6962 - accuracy: 0.9882 - val_loss: 1.0440 - val_accuracy: 0.8329\n","Epoch 45/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6928 - accuracy: 0.9900 - val_loss: 1.0412 - val_accuracy: 0.8356\n","Epoch 46/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6890 - accuracy: 0.9908 - val_loss: 1.0345 - val_accuracy: 0.8384\n","Epoch 47/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6886 - accuracy: 0.9898 - val_loss: 1.0305 - val_accuracy: 0.8438\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6870 - accuracy: 0.9916 - val_loss: 1.0296 - val_accuracy: 0.8438\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6880 - accuracy: 0.9910 - val_loss: 1.0325 - val_accuracy: 0.8384\n","Epoch 50/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6879 - accuracy: 0.9909 - val_loss: 1.0306 - val_accuracy: 0.8493\n","Epoch 51/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6850 - accuracy: 0.9923 - val_loss: 1.0322 - val_accuracy: 0.8438\n","Epoch 52/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6879 - accuracy: 0.9908 - val_loss: 1.0337 - val_accuracy: 0.8438\n","Epoch 53/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6858 - accuracy: 0.9914 - val_loss: 1.0333 - val_accuracy: 0.8384\n","Epoch 54/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6839 - accuracy: 0.9916 - val_loss: 1.0356 - val_accuracy: 0.8411\n","Epoch 55/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6844 - accuracy: 0.9920 - val_loss: 1.0343 - val_accuracy: 0.8438\n","Epoch 56/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6844 - accuracy: 0.9924 - val_loss: 1.0336 - val_accuracy: 0.8438\n","Epoch 57/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6857 - accuracy: 0.9921 - val_loss: 1.0329 - val_accuracy: 0.8438\n","Epoch 58/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6835 - accuracy: 0.9921 - val_loss: 1.0340 - val_accuracy: 0.8411\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6839 - accuracy: 0.9923 - val_loss: 1.0339 - val_accuracy: 0.8411\n","Epoch 60/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6830 - accuracy: 0.9927 - val_loss: 1.0339 - val_accuracy: 0.8411\n","Epoch 61/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6845 - accuracy: 0.9912 - val_loss: 1.0334 - val_accuracy: 0.8438\n","Epoch 62/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6844 - accuracy: 0.9920 - val_loss: 1.0333 - val_accuracy: 0.8411\n","Epoch 63/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6849 - accuracy: 0.9912 - val_loss: 1.0334 - val_accuracy: 0.8411\n","Epoch 64/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6839 - accuracy: 0.9925 - val_loss: 1.0337 - val_accuracy: 0.8384\n","Epoch 65/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6837 - accuracy: 0.9914 - val_loss: 1.0331 - val_accuracy: 0.8411\n","Epoch 66/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6840 - accuracy: 0.9920 - val_loss: 1.0334 - val_accuracy: 0.8411\n","Epoch 67/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6838 - accuracy: 0.9923 - val_loss: 1.0334 - val_accuracy: 0.8411\n","Epoch 68/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6829 - accuracy: 0.9926 - val_loss: 1.0334 - val_accuracy: 0.8411\n","Epoch 69/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6836 - accuracy: 0.9926 - val_loss: 1.0334 - val_accuracy: 0.8411\n","Epoch 70/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6834 - accuracy: 0.9924 - val_loss: 1.0334 - val_accuracy: 0.8411\n","准确率得分： 0.84932\n","Processing fold: 11 (6927, 365)\n","Epoch 1/500\n","273/273 [==============================] - 19s 69ms/step - loss: 2.0077 - accuracy: 0.4318 - val_loss: 1.7181 - val_accuracy: 0.5014\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6524 - accuracy: 0.5682 - val_loss: 1.4570 - val_accuracy: 0.6164\n","Epoch 3/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.4965 - accuracy: 0.6386 - val_loss: 1.4007 - val_accuracy: 0.6630\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3931 - accuracy: 0.6832 - val_loss: 1.2937 - val_accuracy: 0.6959\n","Epoch 5/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3149 - accuracy: 0.7172 - val_loss: 1.2999 - val_accuracy: 0.7288\n","Epoch 6/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.2558 - accuracy: 0.7444 - val_loss: 1.2392 - val_accuracy: 0.7123\n","Epoch 7/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2023 - accuracy: 0.7700 - val_loss: 1.2150 - val_accuracy: 0.7315\n","Epoch 8/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1554 - accuracy: 0.7895 - val_loss: 1.2432 - val_accuracy: 0.7479\n","Epoch 9/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1309 - accuracy: 0.8035 - val_loss: 1.1435 - val_accuracy: 0.7699\n","Epoch 10/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0913 - accuracy: 0.8212 - val_loss: 1.1420 - val_accuracy: 0.7863\n","Epoch 11/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0577 - accuracy: 0.8323 - val_loss: 1.1432 - val_accuracy: 0.7808\n","Epoch 12/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0370 - accuracy: 0.8466 - val_loss: 1.0787 - val_accuracy: 0.8192\n","Epoch 13/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0075 - accuracy: 0.8576 - val_loss: 1.1373 - val_accuracy: 0.8000\n","Epoch 14/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9887 - accuracy: 0.8684 - val_loss: 1.0850 - val_accuracy: 0.8000\n","Epoch 15/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9638 - accuracy: 0.8751 - val_loss: 1.0833 - val_accuracy: 0.8082\n","Epoch 16/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9376 - accuracy: 0.8906 - val_loss: 1.0498 - val_accuracy: 0.8356\n","Epoch 17/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9251 - accuracy: 0.8950 - val_loss: 1.0730 - val_accuracy: 0.8192\n","Epoch 18/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9095 - accuracy: 0.9054 - val_loss: 1.0750 - val_accuracy: 0.8247\n","Epoch 19/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8950 - accuracy: 0.9097 - val_loss: 1.0674 - val_accuracy: 0.8110\n","Epoch 20/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8727 - accuracy: 0.9174 - val_loss: 1.0186 - val_accuracy: 0.8466\n","Epoch 21/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8622 - accuracy: 0.9218 - val_loss: 1.0471 - val_accuracy: 0.8521\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8547 - accuracy: 0.9252 - val_loss: 1.0517 - val_accuracy: 0.8137\n","Epoch 23/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8260 - accuracy: 0.9384 - val_loss: 1.0326 - val_accuracy: 0.8301\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8211 - accuracy: 0.9407 - val_loss: 1.0067 - val_accuracy: 0.8411\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8128 - accuracy: 0.9447 - val_loss: 1.0231 - val_accuracy: 0.8466\n","Epoch 26/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8018 - accuracy: 0.9478 - val_loss: 1.0392 - val_accuracy: 0.8274\n","Epoch 27/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.7979 - accuracy: 0.9500 - val_loss: 1.0757 - val_accuracy: 0.8329\n","Epoch 28/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7909 - accuracy: 0.9525 - val_loss: 1.0918 - val_accuracy: 0.8247\n","Epoch 29/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7780 - accuracy: 0.9558 - val_loss: 1.0410 - val_accuracy: 0.8219\n","Epoch 30/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7323 - accuracy: 0.9763 - val_loss: 0.9785 - val_accuracy: 0.8575\n","Epoch 31/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7122 - accuracy: 0.9839 - val_loss: 0.9714 - val_accuracy: 0.8548\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7054 - accuracy: 0.9872 - val_loss: 0.9649 - val_accuracy: 0.8548\n","Epoch 33/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7030 - accuracy: 0.9858 - val_loss: 0.9769 - val_accuracy: 0.8521\n","Epoch 34/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6991 - accuracy: 0.9886 - val_loss: 0.9721 - val_accuracy: 0.8575\n","Epoch 35/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6993 - accuracy: 0.9872 - val_loss: 0.9752 - val_accuracy: 0.8603\n","Epoch 36/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6937 - accuracy: 0.9901 - val_loss: 0.9689 - val_accuracy: 0.8658\n","Epoch 37/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6927 - accuracy: 0.9894 - val_loss: 0.9634 - val_accuracy: 0.8685\n","Epoch 38/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6910 - accuracy: 0.9902 - val_loss: 0.9674 - val_accuracy: 0.8548\n","Epoch 39/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6890 - accuracy: 0.9905 - val_loss: 0.9902 - val_accuracy: 0.8521\n","Epoch 40/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6859 - accuracy: 0.9911 - val_loss: 0.9848 - val_accuracy: 0.8493\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6847 - accuracy: 0.9909 - val_loss: 0.9674 - val_accuracy: 0.8548\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6819 - accuracy: 0.9925 - val_loss: 0.9684 - val_accuracy: 0.8575\n","Epoch 43/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6829 - accuracy: 0.9924 - val_loss: 0.9665 - val_accuracy: 0.8521\n","Epoch 44/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6794 - accuracy: 0.9927 - val_loss: 0.9753 - val_accuracy: 0.8603\n","Epoch 45/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6793 - accuracy: 0.9930 - val_loss: 0.9865 - val_accuracy: 0.8521\n","Epoch 46/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6767 - accuracy: 0.9935 - val_loss: 0.9775 - val_accuracy: 0.8521\n","Epoch 47/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6752 - accuracy: 0.9933 - val_loss: 0.9755 - val_accuracy: 0.8521\n","Epoch 48/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6747 - accuracy: 0.9940 - val_loss: 0.9754 - val_accuracy: 0.8521\n","Epoch 49/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6738 - accuracy: 0.9947 - val_loss: 0.9723 - val_accuracy: 0.8493\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6749 - accuracy: 0.9935 - val_loss: 0.9708 - val_accuracy: 0.8493\n","Epoch 51/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6740 - accuracy: 0.9943 - val_loss: 0.9719 - val_accuracy: 0.8575\n","Epoch 52/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6735 - accuracy: 0.9931 - val_loss: 0.9701 - val_accuracy: 0.8575\n","Epoch 53/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6736 - accuracy: 0.9941 - val_loss: 0.9738 - val_accuracy: 0.8548\n","Epoch 54/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6727 - accuracy: 0.9943 - val_loss: 0.9732 - val_accuracy: 0.8575\n","Epoch 55/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6734 - accuracy: 0.9933 - val_loss: 0.9730 - val_accuracy: 0.8575\n","Epoch 56/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6744 - accuracy: 0.9944 - val_loss: 0.9725 - val_accuracy: 0.8548\n","Epoch 57/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6737 - accuracy: 0.9941 - val_loss: 0.9722 - val_accuracy: 0.8521\n","准确率得分： 0.86849\n","Processing fold: 12 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0023 - accuracy: 0.4355 - val_loss: 1.6909 - val_accuracy: 0.5549\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6501 - accuracy: 0.5688 - val_loss: 1.5615 - val_accuracy: 0.5632\n","Epoch 3/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.4992 - accuracy: 0.6338 - val_loss: 1.4071 - val_accuracy: 0.6374\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3909 - accuracy: 0.6835 - val_loss: 1.2874 - val_accuracy: 0.7198\n","Epoch 5/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3140 - accuracy: 0.7182 - val_loss: 1.2232 - val_accuracy: 0.7527\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2522 - accuracy: 0.7445 - val_loss: 1.2099 - val_accuracy: 0.7555\n","Epoch 7/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2072 - accuracy: 0.7619 - val_loss: 1.1876 - val_accuracy: 0.7637\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1664 - accuracy: 0.7826 - val_loss: 1.1886 - val_accuracy: 0.7830\n","Epoch 9/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.1308 - accuracy: 0.8034 - val_loss: 1.1748 - val_accuracy: 0.7665\n","Epoch 10/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1000 - accuracy: 0.8162 - val_loss: 1.1313 - val_accuracy: 0.7995\n","Epoch 11/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0699 - accuracy: 0.8290 - val_loss: 1.0862 - val_accuracy: 0.8022\n","Epoch 12/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0464 - accuracy: 0.8394 - val_loss: 1.2544 - val_accuracy: 0.7610\n","Epoch 13/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0214 - accuracy: 0.8493 - val_loss: 1.0995 - val_accuracy: 0.8049\n","Epoch 14/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9962 - accuracy: 0.8627 - val_loss: 1.0564 - val_accuracy: 0.8269\n","Epoch 15/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9765 - accuracy: 0.8705 - val_loss: 1.0502 - val_accuracy: 0.8352\n","Epoch 16/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9510 - accuracy: 0.8813 - val_loss: 1.0307 - val_accuracy: 0.8379\n","Epoch 17/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9330 - accuracy: 0.8912 - val_loss: 1.0246 - val_accuracy: 0.8324\n","Epoch 18/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.9190 - accuracy: 0.8954 - val_loss: 1.0343 - val_accuracy: 0.8324\n","Epoch 19/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.9035 - accuracy: 0.9032 - val_loss: 1.0439 - val_accuracy: 0.8269\n","Epoch 20/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8882 - accuracy: 0.9101 - val_loss: 1.0638 - val_accuracy: 0.8159\n","Epoch 21/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8744 - accuracy: 0.9159 - val_loss: 1.0223 - val_accuracy: 0.8434\n","Epoch 22/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8592 - accuracy: 0.9245 - val_loss: 1.0256 - val_accuracy: 0.8379\n","Epoch 23/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8472 - accuracy: 0.9273 - val_loss: 1.0230 - val_accuracy: 0.8269\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8413 - accuracy: 0.9316 - val_loss: 1.0054 - val_accuracy: 0.8379\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8283 - accuracy: 0.9360 - val_loss: 1.0636 - val_accuracy: 0.8214\n","Epoch 26/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8140 - accuracy: 0.9414 - val_loss: 1.0445 - val_accuracy: 0.8379\n","Epoch 27/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8133 - accuracy: 0.9399 - val_loss: 1.0042 - val_accuracy: 0.8516\n","Epoch 28/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7988 - accuracy: 0.9488 - val_loss: 1.0100 - val_accuracy: 0.8489\n","Epoch 29/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7944 - accuracy: 0.9498 - val_loss: 0.9921 - val_accuracy: 0.8571\n","Epoch 30/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7833 - accuracy: 0.9544 - val_loss: 1.0063 - val_accuracy: 0.8407\n","Epoch 31/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7799 - accuracy: 0.9547 - val_loss: 1.0212 - val_accuracy: 0.8407\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7677 - accuracy: 0.9603 - val_loss: 1.0163 - val_accuracy: 0.8434\n","Epoch 33/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7626 - accuracy: 0.9622 - val_loss: 0.9895 - val_accuracy: 0.8489\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7569 - accuracy: 0.9646 - val_loss: 0.9933 - val_accuracy: 0.8489\n","Epoch 35/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7500 - accuracy: 0.9663 - val_loss: 1.0314 - val_accuracy: 0.8352\n","Epoch 36/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7479 - accuracy: 0.9674 - val_loss: 1.0259 - val_accuracy: 0.8242\n","Epoch 37/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7408 - accuracy: 0.9697 - val_loss: 1.0769 - val_accuracy: 0.8214\n","Epoch 38/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7030 - accuracy: 0.9843 - val_loss: 0.9518 - val_accuracy: 0.8626\n","Epoch 39/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6878 - accuracy: 0.9903 - val_loss: 0.9595 - val_accuracy: 0.8544\n","Epoch 40/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6824 - accuracy: 0.9913 - val_loss: 0.9515 - val_accuracy: 0.8544\n","Epoch 41/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6806 - accuracy: 0.9908 - val_loss: 0.9501 - val_accuracy: 0.8681\n","Epoch 42/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6775 - accuracy: 0.9915 - val_loss: 0.9485 - val_accuracy: 0.8736\n","Epoch 43/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6739 - accuracy: 0.9928 - val_loss: 0.9439 - val_accuracy: 0.8736\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6713 - accuracy: 0.9937 - val_loss: 0.9519 - val_accuracy: 0.8736\n","Epoch 45/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6700 - accuracy: 0.9939 - val_loss: 0.9494 - val_accuracy: 0.8764\n","Epoch 46/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6690 - accuracy: 0.9939 - val_loss: 0.9512 - val_accuracy: 0.8654\n","Epoch 47/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6668 - accuracy: 0.9940 - val_loss: 0.9559 - val_accuracy: 0.8599\n","Epoch 48/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6681 - accuracy: 0.9945 - val_loss: 0.9435 - val_accuracy: 0.8736\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6639 - accuracy: 0.9956 - val_loss: 0.9459 - val_accuracy: 0.8681\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6647 - accuracy: 0.9944 - val_loss: 0.9459 - val_accuracy: 0.8709\n","Epoch 51/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6630 - accuracy: 0.9948 - val_loss: 0.9505 - val_accuracy: 0.8654\n","Epoch 52/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6618 - accuracy: 0.9951 - val_loss: 0.9433 - val_accuracy: 0.8736\n","Epoch 53/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6600 - accuracy: 0.9955 - val_loss: 0.9635 - val_accuracy: 0.8544\n","Epoch 54/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6590 - accuracy: 0.9959 - val_loss: 0.9501 - val_accuracy: 0.8654\n","Epoch 55/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6582 - accuracy: 0.9962 - val_loss: 0.9489 - val_accuracy: 0.8764\n","Epoch 56/500\n","273/273 [==============================] - 17s 63ms/step - loss: 0.6563 - accuracy: 0.9968 - val_loss: 0.9477 - val_accuracy: 0.8681\n","Epoch 57/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6576 - accuracy: 0.9967 - val_loss: 0.9487 - val_accuracy: 0.8709\n","Epoch 58/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6574 - accuracy: 0.9962 - val_loss: 0.9464 - val_accuracy: 0.8681\n","Epoch 59/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6571 - accuracy: 0.9957 - val_loss: 0.9453 - val_accuracy: 0.8709\n","Epoch 60/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6559 - accuracy: 0.9966 - val_loss: 0.9472 - val_accuracy: 0.8681\n","Epoch 61/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6564 - accuracy: 0.9962 - val_loss: 0.9488 - val_accuracy: 0.8736\n","Epoch 62/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6561 - accuracy: 0.9965 - val_loss: 0.9485 - val_accuracy: 0.8736\n","Epoch 63/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6569 - accuracy: 0.9955 - val_loss: 0.9483 - val_accuracy: 0.8709\n","Epoch 64/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6553 - accuracy: 0.9970 - val_loss: 0.9479 - val_accuracy: 0.8736\n","Epoch 65/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6578 - accuracy: 0.9959 - val_loss: 0.9479 - val_accuracy: 0.8736\n","准确率得分： 0.87637\n","Processing fold: 13 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.9917 - accuracy: 0.4353 - val_loss: 1.7094 - val_accuracy: 0.5110\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6384 - accuracy: 0.5735 - val_loss: 1.5349 - val_accuracy: 0.5879\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.4945 - accuracy: 0.6391 - val_loss: 1.4732 - val_accuracy: 0.6071\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3982 - accuracy: 0.6851 - val_loss: 1.4394 - val_accuracy: 0.6456\n","Epoch 5/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3085 - accuracy: 0.7242 - val_loss: 1.3441 - val_accuracy: 0.6813\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2536 - accuracy: 0.7462 - val_loss: 1.3082 - val_accuracy: 0.7033\n","Epoch 7/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1982 - accuracy: 0.7692 - val_loss: 1.2276 - val_accuracy: 0.7280\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1569 - accuracy: 0.7902 - val_loss: 1.2131 - val_accuracy: 0.7308\n","Epoch 9/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1153 - accuracy: 0.8092 - val_loss: 1.1742 - val_accuracy: 0.7665\n","Epoch 10/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0904 - accuracy: 0.8199 - val_loss: 1.1741 - val_accuracy: 0.7885\n","Epoch 11/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0533 - accuracy: 0.8349 - val_loss: 1.1398 - val_accuracy: 0.7637\n","Epoch 12/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0291 - accuracy: 0.8484 - val_loss: 1.1625 - val_accuracy: 0.7802\n","Epoch 13/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0063 - accuracy: 0.8584 - val_loss: 1.1205 - val_accuracy: 0.7940\n","Epoch 14/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.9826 - accuracy: 0.8692 - val_loss: 1.1258 - val_accuracy: 0.7967\n","Epoch 15/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9518 - accuracy: 0.8824 - val_loss: 1.1141 - val_accuracy: 0.7940\n","Epoch 16/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9368 - accuracy: 0.8902 - val_loss: 1.1103 - val_accuracy: 0.7967\n","Epoch 17/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9230 - accuracy: 0.8938 - val_loss: 1.1354 - val_accuracy: 0.7802\n","Epoch 18/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9014 - accuracy: 0.9054 - val_loss: 1.1238 - val_accuracy: 0.7802\n","Epoch 19/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8848 - accuracy: 0.9121 - val_loss: 1.0817 - val_accuracy: 0.8269\n","Epoch 20/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8720 - accuracy: 0.9176 - val_loss: 1.0566 - val_accuracy: 0.8242\n","Epoch 21/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8645 - accuracy: 0.9190 - val_loss: 1.1295 - val_accuracy: 0.8077\n","Epoch 22/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8454 - accuracy: 0.9287 - val_loss: 1.1066 - val_accuracy: 0.7912\n","Epoch 23/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8361 - accuracy: 0.9337 - val_loss: 1.0519 - val_accuracy: 0.8022\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8137 - accuracy: 0.9419 - val_loss: 1.1114 - val_accuracy: 0.7967\n","Epoch 25/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8114 - accuracy: 0.9416 - val_loss: 1.1185 - val_accuracy: 0.8132\n","Epoch 26/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8014 - accuracy: 0.9449 - val_loss: 1.0995 - val_accuracy: 0.8214\n","Epoch 27/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7952 - accuracy: 0.9485 - val_loss: 1.1366 - val_accuracy: 0.8132\n","Epoch 28/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7450 - accuracy: 0.9704 - val_loss: 1.0384 - val_accuracy: 0.8352\n","Epoch 29/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7266 - accuracy: 0.9801 - val_loss: 1.0277 - val_accuracy: 0.8379\n","Epoch 30/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7158 - accuracy: 0.9830 - val_loss: 1.0382 - val_accuracy: 0.8324\n","Epoch 31/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7132 - accuracy: 0.9841 - val_loss: 1.0288 - val_accuracy: 0.8407\n","Epoch 32/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7084 - accuracy: 0.9853 - val_loss: 1.0279 - val_accuracy: 0.8379\n","Epoch 33/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7071 - accuracy: 0.9850 - val_loss: 1.0211 - val_accuracy: 0.8352\n","Epoch 34/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7011 - accuracy: 0.9878 - val_loss: 1.0238 - val_accuracy: 0.8324\n","Epoch 35/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7014 - accuracy: 0.9866 - val_loss: 1.0363 - val_accuracy: 0.8297\n","Epoch 36/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7005 - accuracy: 0.9874 - val_loss: 1.0220 - val_accuracy: 0.8352\n","Epoch 37/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6962 - accuracy: 0.9881 - val_loss: 1.0406 - val_accuracy: 0.8242\n","Epoch 38/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6935 - accuracy: 0.9892 - val_loss: 1.0335 - val_accuracy: 0.8324\n","Epoch 39/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6927 - accuracy: 0.9893 - val_loss: 1.0383 - val_accuracy: 0.8324\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6905 - accuracy: 0.9890 - val_loss: 1.0325 - val_accuracy: 0.8324\n","Epoch 41/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6874 - accuracy: 0.9909 - val_loss: 1.0329 - val_accuracy: 0.8379\n","Epoch 42/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6873 - accuracy: 0.9908 - val_loss: 1.0327 - val_accuracy: 0.8352\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6881 - accuracy: 0.9904 - val_loss: 1.0344 - val_accuracy: 0.8379\n","Epoch 44/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6857 - accuracy: 0.9913 - val_loss: 1.0306 - val_accuracy: 0.8324\n","Epoch 45/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6858 - accuracy: 0.9921 - val_loss: 1.0296 - val_accuracy: 0.8324\n","Epoch 46/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6845 - accuracy: 0.9916 - val_loss: 1.0284 - val_accuracy: 0.8324\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6847 - accuracy: 0.9928 - val_loss: 1.0282 - val_accuracy: 0.8324\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6840 - accuracy: 0.9917 - val_loss: 1.0281 - val_accuracy: 0.8352\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6847 - accuracy: 0.9912 - val_loss: 1.0283 - val_accuracy: 0.8352\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6850 - accuracy: 0.9912 - val_loss: 1.0286 - val_accuracy: 0.8324\n","Epoch 51/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6841 - accuracy: 0.9921 - val_loss: 1.0284 - val_accuracy: 0.8324\n","准确率得分： 0.84066\n","Processing fold: 14 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 69ms/step - loss: 1.9945 - accuracy: 0.4348 - val_loss: 1.6949 - val_accuracy: 0.5495\n","Epoch 2/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.6307 - accuracy: 0.5773 - val_loss: 1.5594 - val_accuracy: 0.5742\n","Epoch 3/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.4889 - accuracy: 0.6377 - val_loss: 1.5049 - val_accuracy: 0.6209\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3833 - accuracy: 0.6886 - val_loss: 1.4193 - val_accuracy: 0.6566\n","Epoch 5/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3167 - accuracy: 0.7145 - val_loss: 1.2740 - val_accuracy: 0.7170\n","Epoch 6/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2479 - accuracy: 0.7511 - val_loss: 1.2510 - val_accuracy: 0.7198\n","Epoch 7/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2018 - accuracy: 0.7711 - val_loss: 1.2279 - val_accuracy: 0.7280\n","Epoch 8/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.1623 - accuracy: 0.7892 - val_loss: 1.1871 - val_accuracy: 0.7363\n","Epoch 9/500\n","273/273 [==============================] - 19s 71ms/step - loss: 1.1259 - accuracy: 0.8039 - val_loss: 1.1702 - val_accuracy: 0.7418\n","Epoch 10/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0842 - accuracy: 0.8258 - val_loss: 1.1421 - val_accuracy: 0.7527\n","Epoch 11/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0626 - accuracy: 0.8364 - val_loss: 1.1193 - val_accuracy: 0.7637\n","Epoch 12/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0287 - accuracy: 0.8488 - val_loss: 1.1232 - val_accuracy: 0.7830\n","Epoch 13/500\n","273/273 [==============================] - 18s 65ms/step - loss: 1.0095 - accuracy: 0.8568 - val_loss: 1.1292 - val_accuracy: 0.7637\n","Epoch 14/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9858 - accuracy: 0.8676 - val_loss: 1.1286 - val_accuracy: 0.7747\n","Epoch 15/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9678 - accuracy: 0.8761 - val_loss: 1.1113 - val_accuracy: 0.7830\n","Epoch 16/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9439 - accuracy: 0.8835 - val_loss: 1.0646 - val_accuracy: 0.8022\n","Epoch 17/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.9271 - accuracy: 0.8944 - val_loss: 1.0535 - val_accuracy: 0.7885\n","Epoch 18/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9099 - accuracy: 0.9009 - val_loss: 1.0505 - val_accuracy: 0.8159\n","Epoch 19/500\n","273/273 [==============================] - 19s 69ms/step - loss: 0.9009 - accuracy: 0.9041 - val_loss: 1.0319 - val_accuracy: 0.8214\n","Epoch 20/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8758 - accuracy: 0.9139 - val_loss: 1.1060 - val_accuracy: 0.7967\n","Epoch 21/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8704 - accuracy: 0.9189 - val_loss: 1.0513 - val_accuracy: 0.8132\n","Epoch 22/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.8535 - accuracy: 0.9235 - val_loss: 1.0019 - val_accuracy: 0.8297\n","Epoch 23/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8420 - accuracy: 0.9311 - val_loss: 1.0485 - val_accuracy: 0.8104\n","Epoch 24/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8288 - accuracy: 0.9364 - val_loss: 1.0747 - val_accuracy: 0.8049\n","Epoch 25/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8255 - accuracy: 0.9367 - val_loss: 1.0090 - val_accuracy: 0.8187\n","Epoch 26/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8117 - accuracy: 0.9418 - val_loss: 1.0548 - val_accuracy: 0.8214\n","Epoch 27/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.8032 - accuracy: 0.9460 - val_loss: 1.0626 - val_accuracy: 0.8159\n","Epoch 28/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7954 - accuracy: 0.9499 - val_loss: 1.0431 - val_accuracy: 0.8242\n","Epoch 29/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7853 - accuracy: 0.9517 - val_loss: 1.0663 - val_accuracy: 0.8104\n","Epoch 30/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7779 - accuracy: 0.9565 - val_loss: 1.0564 - val_accuracy: 0.8214\n","Epoch 31/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7283 - accuracy: 0.9766 - val_loss: 0.9791 - val_accuracy: 0.8434\n","Epoch 32/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7131 - accuracy: 0.9831 - val_loss: 0.9671 - val_accuracy: 0.8489\n","Epoch 33/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7064 - accuracy: 0.9841 - val_loss: 0.9571 - val_accuracy: 0.8489\n","Epoch 34/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.7024 - accuracy: 0.9848 - val_loss: 0.9786 - val_accuracy: 0.8407\n","Epoch 35/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6982 - accuracy: 0.9874 - val_loss: 0.9589 - val_accuracy: 0.8434\n","Epoch 36/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6966 - accuracy: 0.9859 - val_loss: 0.9608 - val_accuracy: 0.8407\n","Epoch 37/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6946 - accuracy: 0.9878 - val_loss: 0.9675 - val_accuracy: 0.8462\n","Epoch 38/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.6926 - accuracy: 0.9885 - val_loss: 0.9610 - val_accuracy: 0.8544\n","Epoch 39/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6889 - accuracy: 0.9887 - val_loss: 0.9667 - val_accuracy: 0.8544\n","Epoch 40/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6895 - accuracy: 0.9894 - val_loss: 0.9703 - val_accuracy: 0.8516\n","Epoch 41/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6883 - accuracy: 0.9878 - val_loss: 0.9593 - val_accuracy: 0.8462\n","Epoch 42/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6838 - accuracy: 0.9898 - val_loss: 0.9757 - val_accuracy: 0.8407\n","Epoch 43/500\n","273/273 [==============================] - 18s 65ms/step - loss: 0.6841 - accuracy: 0.9906 - val_loss: 0.9642 - val_accuracy: 0.8434\n","Epoch 44/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.6815 - accuracy: 0.9901 - val_loss: 0.9616 - val_accuracy: 0.8599\n","Epoch 45/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6821 - accuracy: 0.9898 - val_loss: 0.9665 - val_accuracy: 0.8516\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6783 - accuracy: 0.9905 - val_loss: 0.9736 - val_accuracy: 0.8516\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6790 - accuracy: 0.9916 - val_loss: 0.9715 - val_accuracy: 0.8571\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6770 - accuracy: 0.9919 - val_loss: 0.9770 - val_accuracy: 0.8516\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6749 - accuracy: 0.9927 - val_loss: 0.9773 - val_accuracy: 0.8434\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6751 - accuracy: 0.9915 - val_loss: 0.9694 - val_accuracy: 0.8489\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6727 - accuracy: 0.9924 - val_loss: 0.9832 - val_accuracy: 0.8489\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6722 - accuracy: 0.9930 - val_loss: 0.9828 - val_accuracy: 0.8379\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6695 - accuracy: 0.9936 - val_loss: 0.9762 - val_accuracy: 0.8462\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6680 - accuracy: 0.9936 - val_loss: 0.9778 - val_accuracy: 0.8434\n","Epoch 55/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6670 - accuracy: 0.9944 - val_loss: 0.9735 - val_accuracy: 0.8434\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6678 - accuracy: 0.9935 - val_loss: 0.9725 - val_accuracy: 0.8462\n","Epoch 57/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6679 - accuracy: 0.9940 - val_loss: 0.9750 - val_accuracy: 0.8462\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6663 - accuracy: 0.9944 - val_loss: 0.9762 - val_accuracy: 0.8462\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6664 - accuracy: 0.9939 - val_loss: 0.9729 - val_accuracy: 0.8434\n","Epoch 60/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6670 - accuracy: 0.9940 - val_loss: 0.9731 - val_accuracy: 0.8462\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6652 - accuracy: 0.9947 - val_loss: 0.9727 - val_accuracy: 0.8462\n","Epoch 62/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6666 - accuracy: 0.9939 - val_loss: 0.9725 - val_accuracy: 0.8462\n","Epoch 63/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6656 - accuracy: 0.9948 - val_loss: 0.9728 - val_accuracy: 0.8462\n","Epoch 64/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6655 - accuracy: 0.9940 - val_loss: 0.9728 - val_accuracy: 0.8462\n","准确率得分： 0.85989\n","Processing fold: 15 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0009 - accuracy: 0.4352 - val_loss: 1.6611 - val_accuracy: 0.5467\n","Epoch 2/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.6472 - accuracy: 0.5702 - val_loss: 1.5130 - val_accuracy: 0.6538\n","Epoch 3/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.5032 - accuracy: 0.6310 - val_loss: 1.3872 - val_accuracy: 0.6841\n","Epoch 4/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.3942 - accuracy: 0.6822 - val_loss: 1.2916 - val_accuracy: 0.7335\n","Epoch 5/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.3189 - accuracy: 0.7166 - val_loss: 1.2975 - val_accuracy: 0.6978\n","Epoch 6/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.2516 - accuracy: 0.7468 - val_loss: 1.1993 - val_accuracy: 0.7692\n","Epoch 7/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.2101 - accuracy: 0.7637 - val_loss: 1.1490 - val_accuracy: 0.7637\n","Epoch 8/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.1628 - accuracy: 0.7867 - val_loss: 1.0894 - val_accuracy: 0.7940\n","Epoch 9/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1272 - accuracy: 0.8004 - val_loss: 1.1176 - val_accuracy: 0.7802\n","Epoch 10/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0941 - accuracy: 0.8177 - val_loss: 1.1130 - val_accuracy: 0.7830\n","Epoch 11/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0633 - accuracy: 0.8311 - val_loss: 1.0601 - val_accuracy: 0.8022\n","Epoch 12/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0399 - accuracy: 0.8435 - val_loss: 1.1468 - val_accuracy: 0.7747\n","Epoch 13/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0128 - accuracy: 0.8574 - val_loss: 1.0355 - val_accuracy: 0.8324\n","Epoch 14/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9842 - accuracy: 0.8688 - val_loss: 1.0378 - val_accuracy: 0.8132\n","Epoch 15/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9639 - accuracy: 0.8757 - val_loss: 1.0779 - val_accuracy: 0.8132\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9538 - accuracy: 0.8814 - val_loss: 1.0795 - val_accuracy: 0.8104\n","Epoch 17/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.9349 - accuracy: 0.8883 - val_loss: 1.0019 - val_accuracy: 0.8352\n","Epoch 18/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.9163 - accuracy: 0.8979 - val_loss: 1.0448 - val_accuracy: 0.8407\n","Epoch 19/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.8900 - accuracy: 0.9092 - val_loss: 1.0092 - val_accuracy: 0.8571\n","Epoch 20/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8785 - accuracy: 0.9150 - val_loss: 1.0020 - val_accuracy: 0.8407\n","Epoch 21/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8647 - accuracy: 0.9212 - val_loss: 1.0166 - val_accuracy: 0.8324\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8471 - accuracy: 0.9310 - val_loss: 0.9909 - val_accuracy: 0.8544\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8450 - accuracy: 0.9287 - val_loss: 1.0100 - val_accuracy: 0.8407\n","Epoch 24/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8340 - accuracy: 0.9316 - val_loss: 1.0467 - val_accuracy: 0.8187\n","Epoch 25/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8165 - accuracy: 0.9395 - val_loss: 1.0259 - val_accuracy: 0.8462\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8073 - accuracy: 0.9462 - val_loss: 1.0312 - val_accuracy: 0.8324\n","Epoch 27/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8048 - accuracy: 0.9450 - val_loss: 0.9787 - val_accuracy: 0.8516\n","Epoch 28/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7504 - accuracy: 0.9709 - val_loss: 0.9312 - val_accuracy: 0.8681\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7280 - accuracy: 0.9783 - val_loss: 0.9299 - val_accuracy: 0.8654\n","Epoch 30/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7250 - accuracy: 0.9793 - val_loss: 0.9363 - val_accuracy: 0.8681\n","Epoch 31/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7185 - accuracy: 0.9820 - val_loss: 0.9436 - val_accuracy: 0.8599\n","Epoch 32/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7168 - accuracy: 0.9822 - val_loss: 0.9331 - val_accuracy: 0.8709\n","Epoch 33/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7105 - accuracy: 0.9847 - val_loss: 0.9402 - val_accuracy: 0.8599\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7094 - accuracy: 0.9847 - val_loss: 0.9480 - val_accuracy: 0.8544\n","Epoch 35/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7066 - accuracy: 0.9853 - val_loss: 0.9494 - val_accuracy: 0.8709\n","Epoch 36/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7031 - accuracy: 0.9868 - val_loss: 0.9468 - val_accuracy: 0.8736\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7028 - accuracy: 0.9859 - val_loss: 0.9438 - val_accuracy: 0.8626\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7002 - accuracy: 0.9882 - val_loss: 0.9437 - val_accuracy: 0.8681\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6977 - accuracy: 0.9882 - val_loss: 0.9451 - val_accuracy: 0.8626\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6942 - accuracy: 0.9894 - val_loss: 0.9514 - val_accuracy: 0.8681\n","Epoch 41/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6943 - accuracy: 0.9889 - val_loss: 0.9699 - val_accuracy: 0.8571\n","Epoch 42/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6898 - accuracy: 0.9907 - val_loss: 0.9484 - val_accuracy: 0.8764\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6920 - accuracy: 0.9886 - val_loss: 0.9558 - val_accuracy: 0.8681\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6888 - accuracy: 0.9910 - val_loss: 0.9544 - val_accuracy: 0.8654\n","Epoch 45/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6878 - accuracy: 0.9906 - val_loss: 0.9499 - val_accuracy: 0.8626\n","Epoch 46/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6864 - accuracy: 0.9915 - val_loss: 0.9425 - val_accuracy: 0.8654\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6843 - accuracy: 0.9919 - val_loss: 0.9562 - val_accuracy: 0.8571\n","Epoch 48/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6826 - accuracy: 0.9917 - val_loss: 0.9692 - val_accuracy: 0.8626\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6828 - accuracy: 0.9912 - val_loss: 0.9534 - val_accuracy: 0.8571\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6811 - accuracy: 0.9916 - val_loss: 0.9490 - val_accuracy: 0.8681\n","Epoch 51/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6768 - accuracy: 0.9928 - val_loss: 0.9490 - val_accuracy: 0.8654\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6766 - accuracy: 0.9931 - val_loss: 0.9533 - val_accuracy: 0.8709\n","Epoch 53/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6757 - accuracy: 0.9943 - val_loss: 0.9510 - val_accuracy: 0.8681\n","Epoch 54/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6755 - accuracy: 0.9945 - val_loss: 0.9526 - val_accuracy: 0.8626\n","Epoch 55/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6745 - accuracy: 0.9934 - val_loss: 0.9543 - val_accuracy: 0.8599\n","Epoch 56/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6747 - accuracy: 0.9939 - val_loss: 0.9517 - val_accuracy: 0.8654\n","Epoch 57/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6756 - accuracy: 0.9929 - val_loss: 0.9555 - val_accuracy: 0.8681\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6746 - accuracy: 0.9938 - val_loss: 0.9512 - val_accuracy: 0.8654\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6737 - accuracy: 0.9943 - val_loss: 0.9511 - val_accuracy: 0.8681\n","Epoch 60/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6744 - accuracy: 0.9943 - val_loss: 0.9511 - val_accuracy: 0.8654\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6742 - accuracy: 0.9946 - val_loss: 0.9507 - val_accuracy: 0.8681\n","Epoch 62/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6751 - accuracy: 0.9945 - val_loss: 0.9504 - val_accuracy: 0.8681\n","准确率得分： 0.87637\n","Processing fold: 16 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.9985 - accuracy: 0.4335 - val_loss: 1.7202 - val_accuracy: 0.4973\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6562 - accuracy: 0.5665 - val_loss: 1.5490 - val_accuracy: 0.5632\n","Epoch 3/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.5004 - accuracy: 0.6336 - val_loss: 1.4733 - val_accuracy: 0.6126\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3865 - accuracy: 0.6846 - val_loss: 1.3352 - val_accuracy: 0.6978\n","Epoch 5/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3061 - accuracy: 0.7220 - val_loss: 1.2956 - val_accuracy: 0.7060\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2436 - accuracy: 0.7529 - val_loss: 1.2703 - val_accuracy: 0.7088\n","Epoch 7/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.2042 - accuracy: 0.7690 - val_loss: 1.1924 - val_accuracy: 0.7363\n","Epoch 8/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1565 - accuracy: 0.7897 - val_loss: 1.2979 - val_accuracy: 0.6896\n","Epoch 9/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.1202 - accuracy: 0.8101 - val_loss: 1.1418 - val_accuracy: 0.7775\n","Epoch 10/500\n","273/273 [==============================] - 17s 64ms/step - loss: 1.0856 - accuracy: 0.8235 - val_loss: 1.1771 - val_accuracy: 0.7473\n","Epoch 11/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0641 - accuracy: 0.8319 - val_loss: 1.1097 - val_accuracy: 0.7775\n","Epoch 12/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.0292 - accuracy: 0.8474 - val_loss: 1.1428 - val_accuracy: 0.7857\n","Epoch 13/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0054 - accuracy: 0.8573 - val_loss: 1.1063 - val_accuracy: 0.7775\n","Epoch 14/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.9826 - accuracy: 0.8688 - val_loss: 1.0797 - val_accuracy: 0.7857\n","Epoch 15/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9617 - accuracy: 0.8806 - val_loss: 1.0488 - val_accuracy: 0.8187\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9444 - accuracy: 0.8855 - val_loss: 1.0448 - val_accuracy: 0.8187\n","Epoch 17/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9273 - accuracy: 0.8942 - val_loss: 1.0527 - val_accuracy: 0.8159\n","Epoch 18/500\n","273/273 [==============================] - 19s 70ms/step - loss: 0.9076 - accuracy: 0.9037 - val_loss: 1.0493 - val_accuracy: 0.8269\n","Epoch 19/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8852 - accuracy: 0.9126 - val_loss: 0.9917 - val_accuracy: 0.8434\n","Epoch 20/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8756 - accuracy: 0.9158 - val_loss: 1.0613 - val_accuracy: 0.8214\n","Epoch 21/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8670 - accuracy: 0.9208 - val_loss: 1.0444 - val_accuracy: 0.8187\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8509 - accuracy: 0.9264 - val_loss: 1.0705 - val_accuracy: 0.8022\n","Epoch 23/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8406 - accuracy: 0.9320 - val_loss: 1.0149 - val_accuracy: 0.8324\n","Epoch 24/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8203 - accuracy: 0.9404 - val_loss: 1.0411 - val_accuracy: 0.8187\n","Epoch 25/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8161 - accuracy: 0.9431 - val_loss: 1.0310 - val_accuracy: 0.8352\n","Epoch 26/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8052 - accuracy: 0.9462 - val_loss: 1.0336 - val_accuracy: 0.8214\n","Epoch 27/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7966 - accuracy: 0.9509 - val_loss: 1.0232 - val_accuracy: 0.8379\n","Epoch 28/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7420 - accuracy: 0.9737 - val_loss: 0.9881 - val_accuracy: 0.8462\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7250 - accuracy: 0.9803 - val_loss: 0.9835 - val_accuracy: 0.8462\n","Epoch 30/500\n","273/273 [==============================] - 19s 68ms/step - loss: 0.7186 - accuracy: 0.9824 - val_loss: 0.9755 - val_accuracy: 0.8544\n","Epoch 31/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7148 - accuracy: 0.9844 - val_loss: 0.9844 - val_accuracy: 0.8516\n","Epoch 32/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7093 - accuracy: 0.9847 - val_loss: 0.9720 - val_accuracy: 0.8599\n","Epoch 33/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7060 - accuracy: 0.9870 - val_loss: 0.9779 - val_accuracy: 0.8489\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7046 - accuracy: 0.9858 - val_loss: 0.9738 - val_accuracy: 0.8571\n","Epoch 35/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7037 - accuracy: 0.9869 - val_loss: 0.9779 - val_accuracy: 0.8489\n","Epoch 36/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.7032 - accuracy: 0.9865 - val_loss: 0.9682 - val_accuracy: 0.8654\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6978 - accuracy: 0.9882 - val_loss: 0.9714 - val_accuracy: 0.8599\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6972 - accuracy: 0.9880 - val_loss: 0.9703 - val_accuracy: 0.8516\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6937 - accuracy: 0.9901 - val_loss: 0.9870 - val_accuracy: 0.8516\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6921 - accuracy: 0.9905 - val_loss: 0.9806 - val_accuracy: 0.8626\n","Epoch 41/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6915 - accuracy: 0.9909 - val_loss: 0.9831 - val_accuracy: 0.8489\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6900 - accuracy: 0.9904 - val_loss: 0.9695 - val_accuracy: 0.8462\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6877 - accuracy: 0.9906 - val_loss: 0.9761 - val_accuracy: 0.8489\n","Epoch 44/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6867 - accuracy: 0.9918 - val_loss: 0.9789 - val_accuracy: 0.8544\n","Epoch 45/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6830 - accuracy: 0.9921 - val_loss: 0.9729 - val_accuracy: 0.8626\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6835 - accuracy: 0.9927 - val_loss: 0.9757 - val_accuracy: 0.8599\n","Epoch 47/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6824 - accuracy: 0.9917 - val_loss: 0.9721 - val_accuracy: 0.8681\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6821 - accuracy: 0.9920 - val_loss: 0.9740 - val_accuracy: 0.8681\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6801 - accuracy: 0.9935 - val_loss: 0.9732 - val_accuracy: 0.8654\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6805 - accuracy: 0.9932 - val_loss: 0.9766 - val_accuracy: 0.8681\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6801 - accuracy: 0.9932 - val_loss: 0.9773 - val_accuracy: 0.8599\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6798 - accuracy: 0.9928 - val_loss: 0.9741 - val_accuracy: 0.8654\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6787 - accuracy: 0.9932 - val_loss: 0.9745 - val_accuracy: 0.8681\n","Epoch 54/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6800 - accuracy: 0.9925 - val_loss: 0.9719 - val_accuracy: 0.8654\n","Epoch 55/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6793 - accuracy: 0.9934 - val_loss: 0.9713 - val_accuracy: 0.8654\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6799 - accuracy: 0.9932 - val_loss: 0.9713 - val_accuracy: 0.8654\n","Epoch 57/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6797 - accuracy: 0.9930 - val_loss: 0.9716 - val_accuracy: 0.8654\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6797 - accuracy: 0.9936 - val_loss: 0.9723 - val_accuracy: 0.8654\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6788 - accuracy: 0.9938 - val_loss: 0.9727 - val_accuracy: 0.8681\n","Epoch 60/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6777 - accuracy: 0.9935 - val_loss: 0.9727 - val_accuracy: 0.8654\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6793 - accuracy: 0.9928 - val_loss: 0.9727 - val_accuracy: 0.8681\n","Epoch 62/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6796 - accuracy: 0.9931 - val_loss: 0.9729 - val_accuracy: 0.8681\n","Epoch 63/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6787 - accuracy: 0.9932 - val_loss: 0.9730 - val_accuracy: 0.8681\n","Epoch 64/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6791 - accuracy: 0.9925 - val_loss: 0.9730 - val_accuracy: 0.8681\n","Epoch 65/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6789 - accuracy: 0.9921 - val_loss: 0.9730 - val_accuracy: 0.8681\n","Epoch 66/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6786 - accuracy: 0.9928 - val_loss: 0.9730 - val_accuracy: 0.8681\n","Epoch 67/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6792 - accuracy: 0.9926 - val_loss: 0.9730 - val_accuracy: 0.8681\n","准确率得分： 0.86813\n","Processing fold: 17 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 1.9882 - accuracy: 0.4428 - val_loss: 1.7181 - val_accuracy: 0.5330\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6491 - accuracy: 0.5687 - val_loss: 1.5877 - val_accuracy: 0.5852\n","Epoch 3/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.4970 - accuracy: 0.6364 - val_loss: 1.5184 - val_accuracy: 0.5934\n","Epoch 4/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3889 - accuracy: 0.6827 - val_loss: 1.3582 - val_accuracy: 0.6648\n","Epoch 5/500\n","273/273 [==============================] - 19s 68ms/step - loss: 1.3114 - accuracy: 0.7208 - val_loss: 1.3259 - val_accuracy: 0.6731\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2536 - accuracy: 0.7453 - val_loss: 1.2980 - val_accuracy: 0.7115\n","Epoch 7/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2004 - accuracy: 0.7705 - val_loss: 1.2663 - val_accuracy: 0.7143\n","Epoch 8/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.1594 - accuracy: 0.7920 - val_loss: 1.2170 - val_accuracy: 0.7335\n","Epoch 9/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1334 - accuracy: 0.8022 - val_loss: 1.1477 - val_accuracy: 0.7802\n","Epoch 10/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1006 - accuracy: 0.8170 - val_loss: 1.1724 - val_accuracy: 0.7720\n","Epoch 11/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0633 - accuracy: 0.8321 - val_loss: 1.1756 - val_accuracy: 0.7747\n","Epoch 12/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0376 - accuracy: 0.8437 - val_loss: 1.0893 - val_accuracy: 0.7885\n","Epoch 13/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.0085 - accuracy: 0.8561 - val_loss: 1.1256 - val_accuracy: 0.7940\n","Epoch 14/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9939 - accuracy: 0.8633 - val_loss: 1.1168 - val_accuracy: 0.7747\n","Epoch 15/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9721 - accuracy: 0.8757 - val_loss: 1.1678 - val_accuracy: 0.7747\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9465 - accuracy: 0.8833 - val_loss: 1.0911 - val_accuracy: 0.7940\n","Epoch 17/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9312 - accuracy: 0.8928 - val_loss: 1.0751 - val_accuracy: 0.8242\n","Epoch 18/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9125 - accuracy: 0.8996 - val_loss: 1.0868 - val_accuracy: 0.8104\n","Epoch 19/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8974 - accuracy: 0.9056 - val_loss: 1.0555 - val_accuracy: 0.8077\n","Epoch 20/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8880 - accuracy: 0.9127 - val_loss: 1.0660 - val_accuracy: 0.8132\n","Epoch 21/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8746 - accuracy: 0.9166 - val_loss: 1.0856 - val_accuracy: 0.8077\n","Epoch 22/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8630 - accuracy: 0.9216 - val_loss: 1.0260 - val_accuracy: 0.8379\n","Epoch 23/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8472 - accuracy: 0.9293 - val_loss: 1.0956 - val_accuracy: 0.8159\n","Epoch 24/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8333 - accuracy: 0.9338 - val_loss: 1.0656 - val_accuracy: 0.8434\n","Epoch 25/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8228 - accuracy: 0.9383 - val_loss: 1.0554 - val_accuracy: 0.8159\n","Epoch 26/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8187 - accuracy: 0.9388 - val_loss: 1.0321 - val_accuracy: 0.8379\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8069 - accuracy: 0.9444 - val_loss: 1.0088 - val_accuracy: 0.8352\n","Epoch 28/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7990 - accuracy: 0.9473 - val_loss: 1.0800 - val_accuracy: 0.8214\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7960 - accuracy: 0.9500 - val_loss: 1.0013 - val_accuracy: 0.8407\n","Epoch 30/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7841 - accuracy: 0.9531 - val_loss: 1.0450 - val_accuracy: 0.8159\n","Epoch 31/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7800 - accuracy: 0.9564 - val_loss: 1.0518 - val_accuracy: 0.8324\n","Epoch 32/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7628 - accuracy: 0.9632 - val_loss: 1.0686 - val_accuracy: 0.8187\n","Epoch 33/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7273 - accuracy: 0.9762 - val_loss: 0.9882 - val_accuracy: 0.8352\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7076 - accuracy: 0.9846 - val_loss: 0.9893 - val_accuracy: 0.8324\n","Epoch 35/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7018 - accuracy: 0.9866 - val_loss: 0.9931 - val_accuracy: 0.8242\n","Epoch 36/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6988 - accuracy: 0.9860 - val_loss: 0.9903 - val_accuracy: 0.8379\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6962 - accuracy: 0.9870 - val_loss: 1.0118 - val_accuracy: 0.8269\n","Epoch 38/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6931 - accuracy: 0.9881 - val_loss: 0.9862 - val_accuracy: 0.8379\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6915 - accuracy: 0.9893 - val_loss: 0.9911 - val_accuracy: 0.8379\n","Epoch 40/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6903 - accuracy: 0.9888 - val_loss: 1.0152 - val_accuracy: 0.8407\n","Epoch 41/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6869 - accuracy: 0.9901 - val_loss: 1.0015 - val_accuracy: 0.8434\n","Epoch 42/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6846 - accuracy: 0.9911 - val_loss: 0.9994 - val_accuracy: 0.8434\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6854 - accuracy: 0.9905 - val_loss: 0.9978 - val_accuracy: 0.8379\n","Epoch 44/500\n","273/273 [==============================] - 18s 68ms/step - loss: 0.6844 - accuracy: 0.9909 - val_loss: 0.9950 - val_accuracy: 0.8462\n","Epoch 45/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6840 - accuracy: 0.9908 - val_loss: 0.9946 - val_accuracy: 0.8407\n","Epoch 46/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6832 - accuracy: 0.9919 - val_loss: 0.9931 - val_accuracy: 0.8434\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6833 - accuracy: 0.9912 - val_loss: 0.9910 - val_accuracy: 0.8462\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6821 - accuracy: 0.9916 - val_loss: 0.9911 - val_accuracy: 0.8434\n","Epoch 49/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6810 - accuracy: 0.9925 - val_loss: 0.9947 - val_accuracy: 0.8462\n","Epoch 50/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6829 - accuracy: 0.9905 - val_loss: 0.9925 - val_accuracy: 0.8434\n","Epoch 51/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6820 - accuracy: 0.9920 - val_loss: 0.9909 - val_accuracy: 0.8462\n","Epoch 52/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6806 - accuracy: 0.9918 - val_loss: 0.9927 - val_accuracy: 0.8434\n","Epoch 53/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6819 - accuracy: 0.9911 - val_loss: 0.9928 - val_accuracy: 0.8462\n","Epoch 54/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6822 - accuracy: 0.9912 - val_loss: 0.9932 - val_accuracy: 0.8462\n","Epoch 55/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6812 - accuracy: 0.9923 - val_loss: 0.9934 - val_accuracy: 0.8489\n","Epoch 56/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6796 - accuracy: 0.9924 - val_loss: 0.9933 - val_accuracy: 0.8462\n","Epoch 57/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6803 - accuracy: 0.9919 - val_loss: 0.9931 - val_accuracy: 0.8462\n","Epoch 58/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6822 - accuracy: 0.9909 - val_loss: 0.9932 - val_accuracy: 0.8489\n","Epoch 59/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6816 - accuracy: 0.9910 - val_loss: 0.9935 - val_accuracy: 0.8489\n","Epoch 60/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6801 - accuracy: 0.9927 - val_loss: 0.9935 - val_accuracy: 0.8489\n","Epoch 61/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6811 - accuracy: 0.9916 - val_loss: 0.9932 - val_accuracy: 0.8489\n","Epoch 62/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6818 - accuracy: 0.9915 - val_loss: 0.9928 - val_accuracy: 0.8489\n","Epoch 63/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6807 - accuracy: 0.9923 - val_loss: 0.9926 - val_accuracy: 0.8489\n","Epoch 64/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6807 - accuracy: 0.9918 - val_loss: 0.9927 - val_accuracy: 0.8489\n","Epoch 65/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6813 - accuracy: 0.9915 - val_loss: 0.9927 - val_accuracy: 0.8489\n","Epoch 66/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6810 - accuracy: 0.9924 - val_loss: 0.9927 - val_accuracy: 0.8489\n","Epoch 67/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6820 - accuracy: 0.9912 - val_loss: 0.9927 - val_accuracy: 0.8489\n","Epoch 68/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6800 - accuracy: 0.9919 - val_loss: 0.9927 - val_accuracy: 0.8489\n","Epoch 69/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6807 - accuracy: 0.9910 - val_loss: 0.9927 - val_accuracy: 0.8489\n","Epoch 70/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6804 - accuracy: 0.9919 - val_loss: 0.9928 - val_accuracy: 0.8489\n","Epoch 71/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6793 - accuracy: 0.9921 - val_loss: 0.9928 - val_accuracy: 0.8489\n","Epoch 72/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6798 - accuracy: 0.9932 - val_loss: 0.9928 - val_accuracy: 0.8489\n","Epoch 73/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6814 - accuracy: 0.9912 - val_loss: 0.9928 - val_accuracy: 0.8489\n","Epoch 74/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6797 - accuracy: 0.9931 - val_loss: 0.9928 - val_accuracy: 0.8489\n","Epoch 75/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6808 - accuracy: 0.9912 - val_loss: 0.9928 - val_accuracy: 0.8489\n","准确率得分： 0.8489\n","Processing fold: 18 (6928, 364)\n","Epoch 1/500\n","273/273 [==============================] - 19s 70ms/step - loss: 2.0076 - accuracy: 0.4308 - val_loss: 1.5931 - val_accuracy: 0.5549\n","Epoch 2/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.6508 - accuracy: 0.5717 - val_loss: 1.4973 - val_accuracy: 0.5962\n","Epoch 3/500\n","273/273 [==============================] - 20s 74ms/step - loss: 1.5035 - accuracy: 0.6363 - val_loss: 1.3706 - val_accuracy: 0.6786\n","Epoch 4/500\n","273/273 [==============================] - 18s 68ms/step - loss: 1.3960 - accuracy: 0.6791 - val_loss: 1.3669 - val_accuracy: 0.6868\n","Epoch 5/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.3222 - accuracy: 0.7153 - val_loss: 1.2851 - val_accuracy: 0.6923\n","Epoch 6/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.2581 - accuracy: 0.7455 - val_loss: 1.1969 - val_accuracy: 0.7582\n","Epoch 7/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.2078 - accuracy: 0.7690 - val_loss: 1.2025 - val_accuracy: 0.7390\n","Epoch 8/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.1736 - accuracy: 0.7803 - val_loss: 1.1513 - val_accuracy: 0.7747\n","Epoch 9/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.1302 - accuracy: 0.8001 - val_loss: 1.1643 - val_accuracy: 0.7747\n","Epoch 10/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0962 - accuracy: 0.8195 - val_loss: 1.1702 - val_accuracy: 0.7445\n","Epoch 11/500\n","273/273 [==============================] - 18s 64ms/step - loss: 1.0675 - accuracy: 0.8291 - val_loss: 1.1866 - val_accuracy: 0.7665\n","Epoch 12/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0366 - accuracy: 0.8457 - val_loss: 1.1054 - val_accuracy: 0.7912\n","Epoch 13/500\n","273/273 [==============================] - 18s 67ms/step - loss: 1.0127 - accuracy: 0.8546 - val_loss: 1.0422 - val_accuracy: 0.8242\n","Epoch 14/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9936 - accuracy: 0.8627 - val_loss: 1.1022 - val_accuracy: 0.7912\n","Epoch 15/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9655 - accuracy: 0.8774 - val_loss: 1.0279 - val_accuracy: 0.8214\n","Epoch 16/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9435 - accuracy: 0.8859 - val_loss: 1.0615 - val_accuracy: 0.7995\n","Epoch 17/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.9315 - accuracy: 0.8918 - val_loss: 1.0330 - val_accuracy: 0.8324\n","Epoch 18/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.9113 - accuracy: 0.9026 - val_loss: 1.0541 - val_accuracy: 0.8297\n","Epoch 19/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8969 - accuracy: 0.9094 - val_loss: 1.0481 - val_accuracy: 0.8187\n","Epoch 20/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8749 - accuracy: 0.9157 - val_loss: 1.0358 - val_accuracy: 0.8214\n","Epoch 21/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8684 - accuracy: 0.9190 - val_loss: 1.0454 - val_accuracy: 0.8214\n","Epoch 22/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8553 - accuracy: 0.9254 - val_loss: 1.0349 - val_accuracy: 0.8269\n","Epoch 23/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8421 - accuracy: 0.9328 - val_loss: 1.0058 - val_accuracy: 0.8352\n","Epoch 24/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.8287 - accuracy: 0.9373 - val_loss: 1.0167 - val_accuracy: 0.8489\n","Epoch 25/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.8253 - accuracy: 0.9363 - val_loss: 0.9885 - val_accuracy: 0.8407\n","Epoch 26/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.8089 - accuracy: 0.9429 - val_loss: 1.0340 - val_accuracy: 0.8324\n","Epoch 27/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7984 - accuracy: 0.9496 - val_loss: 1.0394 - val_accuracy: 0.8352\n","Epoch 28/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7882 - accuracy: 0.9546 - val_loss: 1.0249 - val_accuracy: 0.8516\n","Epoch 29/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7809 - accuracy: 0.9574 - val_loss: 1.0105 - val_accuracy: 0.8352\n","Epoch 30/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7808 - accuracy: 0.9550 - val_loss: 1.0019 - val_accuracy: 0.8407\n","Epoch 31/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7735 - accuracy: 0.9593 - val_loss: 1.0598 - val_accuracy: 0.8269\n","Epoch 32/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7659 - accuracy: 0.9615 - val_loss: 0.9900 - val_accuracy: 0.8516\n","Epoch 33/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7597 - accuracy: 0.9633 - val_loss: 1.0398 - val_accuracy: 0.8324\n","Epoch 34/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7518 - accuracy: 0.9672 - val_loss: 1.0308 - val_accuracy: 0.8462\n","Epoch 35/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7482 - accuracy: 0.9672 - val_loss: 1.0310 - val_accuracy: 0.8434\n","Epoch 36/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.7439 - accuracy: 0.9694 - val_loss: 1.0165 - val_accuracy: 0.8571\n","Epoch 37/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7348 - accuracy: 0.9731 - val_loss: 1.1089 - val_accuracy: 0.8269\n","Epoch 38/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7297 - accuracy: 0.9736 - val_loss: 1.0279 - val_accuracy: 0.8352\n","Epoch 39/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7335 - accuracy: 0.9724 - val_loss: 1.0435 - val_accuracy: 0.8242\n","Epoch 40/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7234 - accuracy: 0.9757 - val_loss: 1.0677 - val_accuracy: 0.8297\n","Epoch 41/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7208 - accuracy: 0.9761 - val_loss: 1.0457 - val_accuracy: 0.8516\n","Epoch 42/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7185 - accuracy: 0.9766 - val_loss: 1.0232 - val_accuracy: 0.8462\n","Epoch 43/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.7197 - accuracy: 0.9775 - val_loss: 1.0272 - val_accuracy: 0.8462\n","Epoch 44/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.7115 - accuracy: 0.9792 - val_loss: 1.0508 - val_accuracy: 0.8379\n","Epoch 45/500\n","273/273 [==============================] - 18s 67ms/step - loss: 0.6813 - accuracy: 0.9893 - val_loss: 0.9866 - val_accuracy: 0.8791\n","Epoch 46/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6671 - accuracy: 0.9940 - val_loss: 0.9881 - val_accuracy: 0.8736\n","Epoch 47/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6628 - accuracy: 0.9950 - val_loss: 0.9920 - val_accuracy: 0.8654\n","Epoch 48/500\n","273/273 [==============================] - 18s 64ms/step - loss: 0.6602 - accuracy: 0.9953 - val_loss: 0.9879 - val_accuracy: 0.8709\n","Epoch 49/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6584 - accuracy: 0.9950 - val_loss: 0.9831 - val_accuracy: 0.8681\n","Epoch 50/500\n","273/273 [==============================] - 17s 64ms/step - loss: 0.6569 - accuracy: 0.9958 - val_loss: 0.9906 - val_accuracy: 0.8709\n","Epoch 51/500\n","244/273 [=========================>....] - ETA: 1s - loss: 0.6571 - accuracy: 0.9949"],"name":"stdout"}]}]}